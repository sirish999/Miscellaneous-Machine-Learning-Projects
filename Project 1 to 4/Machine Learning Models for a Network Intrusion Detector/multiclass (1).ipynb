{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:From C:\\Users\\siris\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/1000\n",
      "175341/175341 - 8s - loss: 1.7719 - val_loss: 1.6908\n",
      "Epoch 2/1000\n",
      "175341/175341 - 3s - loss: 1.6895 - val_loss: 1.6905\n",
      "Epoch 3/1000\n",
      "175341/175341 - 3s - loss: 1.6895 - val_loss: 1.6899\n",
      "Epoch 4/1000\n",
      "175341/175341 - 3s - loss: 1.6894 - val_loss: 1.6899\n",
      "Epoch 5/1000\n",
      "175341/175341 - 3s - loss: 1.6892 - val_loss: 1.6900\n",
      "Epoch 6/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6898\n",
      "Epoch 00006: early stopping\n",
      "1\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/1000\n",
      "175341/175341 - 3s - loss: 1.7232 - val_loss: 1.6911\n",
      "Epoch 2/1000\n",
      "175341/175341 - 3s - loss: 1.6898 - val_loss: 1.6901\n",
      "Epoch 3/1000\n",
      "175341/175341 - 3s - loss: 1.6894 - val_loss: 1.6898\n",
      "Epoch 4/1000\n",
      "175341/175341 - 3s - loss: 1.6894 - val_loss: 1.6905\n",
      "Epoch 5/1000\n",
      "175341/175341 - 3s - loss: 1.6894 - val_loss: 1.6897\n",
      "Epoch 6/1000\n",
      "175341/175341 - 3s - loss: 1.6894 - val_loss: 1.6896\n",
      "Epoch 7/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6899\n",
      "Epoch 00007: early stopping\n",
      "2\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/1000\n",
      "175341/175341 - 4s - loss: 1.7267 - val_loss: 1.6903\n",
      "Epoch 2/1000\n",
      "175341/175341 - 3s - loss: 1.6895 - val_loss: 1.6896\n",
      "Epoch 3/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6899\n",
      "Epoch 4/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6913\n",
      "Epoch 5/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6900\n",
      "Epoch 6/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6898\n",
      "Epoch 00006: early stopping\n",
      "3\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/1000\n",
      "175341/175341 - 4s - loss: 1.7224 - val_loss: 1.6902\n",
      "Epoch 2/1000\n",
      "175341/175341 - 3s - loss: 1.6896 - val_loss: 1.6898\n",
      "Epoch 3/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6897\n",
      "Epoch 4/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6898\n",
      "Epoch 5/1000\n",
      "175341/175341 - 3s - loss: 1.6893 - val_loss: 1.6896\n",
      "Epoch 6/1000\n",
      "175341/175341 - 3s - loss: 1.6892 - val_loss: 1.6899\n",
      "Epoch 00006: early stopping\n",
      "4\n",
      "Train on 175341 samples, validate on 82332 samples\n",
      "Epoch 1/1000\n",
      "175341/175341 - 3s - loss: 1.7296 - val_loss: 1.6901\n",
      "Epoch 2/1000\n",
      "175341/175341 - 3s - loss: 1.6895 - val_loss: 1.6900\n",
      "Epoch 3/1000\n",
      "175341/175341 - 3s - loss: 1.6895 - val_loss: 1.6902\n",
      "Epoch 4/1000\n",
      "175341/175341 - 3s - loss: 1.6894 - val_loss: 1.6897\n",
      "Epoch 5/1000\n",
      "175341/175341 - 3s - loss: 1.6894 - val_loss: 1.6898\n",
      "Epoch 6/1000\n",
      "175341/175341 - 3s - loss: 1.6894 - val_loss: 1.6899\n",
      "Epoch 00006: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n",
      "[6 6 6 ... 6 6 6]\n",
      "Accuracy score: 0.36140261380751104\n",
      "Precision score: 0.13061184926690098\n",
      "Recall score: 0.36140261380751104\n",
      "F1 score: 0.1918783583081444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siris\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\siris\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "preprocess = True\n",
    "\n",
    "\n",
    "\n",
    "filename_read = os.path.join(r\"C:\\Users\\siris\\OneDrive\\Desktop\\datasets\\PROJECT1A\\combined_csv.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "#df = df[df.attack_cat != 'Normal']\n",
    "#df.drop(columns=['label'])\n",
    "# create feature vector\n",
    "encode_text_dummy(df, 'proto')\n",
    "encode_text_dummy(df, 'service')\n",
    "encode_text_dummy(df, 'state')\n",
    "encode_text_index(df, 'attack_cat')\n",
    "\n",
    "\n",
    "if preprocess:\n",
    "    encode_numeric_zscore(df, 'dur')\n",
    "    encode_numeric_zscore(df, 'spkts')\n",
    "    encode_numeric_zscore(df, 'dpkts')\n",
    "    encode_numeric_zscore(df, 'sbytes')\n",
    "    encode_numeric_zscore(df, 'dbytes')\n",
    "    encode_numeric_zscore(df, 'rate')\n",
    "    encode_numeric_zscore(df, 'sttl')\n",
    "    encode_numeric_zscore(df, 'dttl')\n",
    "    encode_numeric_zscore(df, 'sload')\n",
    "    encode_numeric_zscore(df, 'dload')\n",
    "    encode_numeric_zscore(df, 'sloss')\n",
    "    encode_numeric_zscore(df, 'dloss')\n",
    "    encode_numeric_zscore(df, 'sinpkt')\n",
    "    encode_numeric_zscore(df, 'dinpkt')\n",
    "    encode_numeric_zscore(df, 'sjit')\n",
    "    encode_numeric_zscore(df, 'djit')\n",
    "    encode_numeric_zscore(df, 'swin')\n",
    "    encode_numeric_zscore(df, 'stcpb')\n",
    "    encode_numeric_zscore(df, 'dtcpb')\n",
    "    encode_numeric_zscore(df, 'dwin')\n",
    "    encode_numeric_zscore(df, 'tcprtt')\n",
    "    encode_numeric_zscore(df, 'ackdat')\n",
    "    encode_numeric_zscore(df, 'smean')\n",
    "    encode_numeric_zscore(df, 'dmean')\n",
    "    encode_numeric_zscore(df, 'trans_depth')\n",
    "    encode_numeric_zscore(df, 'response_body_len')\n",
    "    encode_numeric_zscore(df, 'ct_srv_src')\n",
    "    encode_numeric_zscore(df, 'ct_state_ttl')\n",
    "    encode_numeric_zscore(df, 'ct_dst_ltm')\n",
    "    encode_numeric_zscore(df, 'ct_src_dport_ltm')\n",
    "    encode_numeric_zscore(df, 'ct_dst_sport_ltm')\n",
    "    encode_numeric_zscore(df, 'is_ftp_login')\n",
    "    encode_numeric_zscore(df, 'ct_ftp_cmd')\n",
    "    encode_numeric_zscore(df, 'ct_flw_http_mthd')\n",
    "    encode_numeric_zscore(df, 'ct_src_ltm')\n",
    "    encode_numeric_zscore(df, 'ct_srv_dst')\n",
    "    encode_numeric_zscore(df, 'is_sm_ips_ports')\n",
    "    \n",
    "x,y = to_xy(df,'attack_cat')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x , y , test_size=0.3195179336, random_state=42)\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=r\"C:\\Users\\siris\\OneDrive\\Desktop\\datasets\\PROJECT1A\\best_weights.hdf5\", verbose=0, save_best_only=True)\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "     # save best model\n",
    "\n",
    "    # batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test), batch_size= 128, callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "print('Training finished...Loading the best model')  \n",
    "print()\n",
    "model.load_weights(r\"C:\\Users\\siris\\OneDrive\\Desktop\\datasets\\PROJECT1A\\best_weights.hdf5\") # load weights from best model\n",
    "\n",
    "# Predict and measure RMSE\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "pred = np.argmax(pred,axis=1) # raw probabilities to choose class (highest probability)\n",
    "print(pred)\n",
    "\n",
    "\n",
    "y_true= np.argmax(y_test,axis=1) \n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "\n",
    "score = metrics.precision_score(y_true, pred, average= \"weighted\")\n",
    "print(\"Precision score: {}\".format(score))\n",
    "\n",
    "score = metrics.recall_score(y_true, pred, average= \"weighted\")\n",
    "print(\"Recall score: {}\".format(score))\n",
    "\n",
    "\n",
    "score = metrics.f1_score(y_true, pred, average= \"weighted\")\n",
    "print(\"F1 score: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
