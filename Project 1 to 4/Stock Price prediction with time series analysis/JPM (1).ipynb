{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "    \n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "    \n",
    "\n",
    "preprocess = True\n",
    "\n",
    "filename_read = os.path.join(r\"C:\\Users\\siris\\OneDrive\\Desktop\\215\\mini-project2\\JPM.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "df.drop('Adj Close', axis=1, inplace=True)\n",
    "if preprocess:\n",
    "    encode_numeric_zscore(df, 'Open')\n",
    "    encode_numeric_zscore(df, 'High')\n",
    "    encode_numeric_zscore(df, 'Low')\n",
    "    encode_numeric_zscore(df, 'Volume')\n",
    "\n",
    "    \n",
    "x,y = to_xy(df,'Close')\n",
    "\n",
    "y2=df.Close\n",
    "encode_numeric_zscore(df, 'Close')\n",
    "y2=y2.values.astype(np.float32)\n",
    "x=np.concatenate((x, y[:,None]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "last = y.shape[0]\n",
    "i = 0\n",
    "#X_Row = np.concatenate((x[i],y[i]), axis=None)\n",
    "X_Row = x[i]\n",
    "for j in range(1,6):\n",
    "    X_Row = np.concatenate((X_Row, x[i+j]), axis=None)\n",
    "X = X_Row\n",
    "Y = y[6]\n",
    "i = i + 1\n",
    "\n",
    "while i < (last-10):\n",
    "    X_Row = x[i]\n",
    "    for j in range(1,6):\n",
    "        X_Row = np.concatenate((X_Row, x[i+j]), axis=None)\n",
    "    X = np.vstack((X, X_Row))\n",
    "    Y = np.concatenate((Y, y[i+6]), axis=None)    \n",
    "    i = i + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X , Y , test_size=0.30, random_state=42)\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 6814 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6814/6814 - 0s - loss: 441.5941 - val_loss: 8.3329\n",
      "Epoch 2/1000\n",
      "6814/6814 - 0s - loss: 4.0118 - val_loss: 1.8500\n",
      "Epoch 3/1000\n",
      "6814/6814 - 0s - loss: 1.7617 - val_loss: 1.5850\n",
      "Epoch 4/1000\n",
      "6814/6814 - 0s - loss: 1.6448 - val_loss: 1.5485\n",
      "Epoch 5/1000\n",
      "6814/6814 - 0s - loss: 1.6242 - val_loss: 1.5340\n",
      "Epoch 6/1000\n",
      "6814/6814 - 0s - loss: 1.6080 - val_loss: 1.5207\n",
      "Epoch 7/1000\n",
      "6814/6814 - 0s - loss: 1.5940 - val_loss: 1.5080\n",
      "Epoch 8/1000\n",
      "6814/6814 - 0s - loss: 1.5801 - val_loss: 1.4956\n",
      "Epoch 9/1000\n",
      "6814/6814 - 0s - loss: 1.5689 - val_loss: 1.4826\n",
      "Epoch 10/1000\n",
      "6814/6814 - 0s - loss: 1.5517 - val_loss: 1.4712\n",
      "Epoch 11/1000\n",
      "6814/6814 - 0s - loss: 1.5395 - val_loss: 1.4594\n",
      "Epoch 12/1000\n",
      "6814/6814 - 0s - loss: 1.5293 - val_loss: 1.4487\n",
      "Epoch 13/1000\n",
      "6814/6814 - 0s - loss: 1.5140 - val_loss: 1.4601\n",
      "Epoch 14/1000\n",
      "6814/6814 - 0s - loss: 1.5078 - val_loss: 1.4320\n",
      "Epoch 15/1000\n",
      "6814/6814 - 0s - loss: 1.4908 - val_loss: 1.4278\n",
      "Epoch 16/1000\n",
      "6814/6814 - 0s - loss: 1.4813 - val_loss: 1.4070\n",
      "Epoch 17/1000\n",
      "6814/6814 - 0s - loss: 1.4692 - val_loss: 1.4215\n",
      "Epoch 18/1000\n",
      "6814/6814 - 0s - loss: 1.4637 - val_loss: 1.3885\n",
      "Epoch 19/1000\n",
      "6814/6814 - 0s - loss: 1.4501 - val_loss: 1.3817\n",
      "Epoch 20/1000\n",
      "6814/6814 - 0s - loss: 1.4446 - val_loss: 1.3727\n",
      "Epoch 21/1000\n",
      "6814/6814 - 0s - loss: 1.4359 - val_loss: 1.3604\n",
      "Epoch 22/1000\n",
      "6814/6814 - 0s - loss: 1.4331 - val_loss: 1.3538\n",
      "Epoch 23/1000\n",
      "6814/6814 - 0s - loss: 1.4125 - val_loss: 1.3623\n",
      "Epoch 24/1000\n",
      "6814/6814 - 0s - loss: 1.4019 - val_loss: 1.3387\n",
      "Epoch 25/1000\n",
      "6814/6814 - 0s - loss: 1.3892 - val_loss: 1.3291\n",
      "Epoch 26/1000\n",
      "6814/6814 - 0s - loss: 1.3800 - val_loss: 1.3134\n",
      "Epoch 27/1000\n",
      "6814/6814 - 0s - loss: 1.3702 - val_loss: 1.3131\n",
      "Epoch 28/1000\n",
      "6814/6814 - 0s - loss: 1.3642 - val_loss: 1.3102\n",
      "Epoch 29/1000\n",
      "6814/6814 - 0s - loss: 1.3563 - val_loss: 1.2765\n",
      "Epoch 30/1000\n",
      "6814/6814 - 0s - loss: 1.3437 - val_loss: 1.2788\n",
      "Epoch 31/1000\n",
      "6814/6814 - 0s - loss: 1.3233 - val_loss: 1.2576\n",
      "Epoch 32/1000\n",
      "6814/6814 - 0s - loss: 1.3179 - val_loss: 1.2426\n",
      "Epoch 33/1000\n",
      "6814/6814 - 0s - loss: 1.2995 - val_loss: 1.2309\n",
      "Epoch 34/1000\n",
      "6814/6814 - 0s - loss: 1.2911 - val_loss: 1.2217\n",
      "Epoch 35/1000\n",
      "6814/6814 - 0s - loss: 1.2726 - val_loss: 1.2052\n",
      "Epoch 36/1000\n",
      "6814/6814 - 0s - loss: 1.2639 - val_loss: 1.2253\n",
      "Epoch 37/1000\n",
      "6814/6814 - 0s - loss: 1.2695 - val_loss: 1.2230\n",
      "Epoch 38/1000\n",
      "6814/6814 - 0s - loss: 1.2396 - val_loss: 1.1944\n",
      "Epoch 39/1000\n",
      "6814/6814 - 0s - loss: 1.2177 - val_loss: 1.1438\n",
      "Epoch 40/1000\n",
      "6814/6814 - 0s - loss: 1.1905 - val_loss: 1.1264\n",
      "Epoch 41/1000\n",
      "6814/6814 - 0s - loss: 1.1736 - val_loss: 1.1298\n",
      "Epoch 42/1000\n",
      "6814/6814 - 0s - loss: 1.1643 - val_loss: 1.1008\n",
      "Epoch 43/1000\n",
      "6814/6814 - 0s - loss: 1.1518 - val_loss: 1.1059\n",
      "Epoch 44/1000\n",
      "6814/6814 - 0s - loss: 1.1460 - val_loss: 1.2270\n",
      "Epoch 45/1000\n",
      "6814/6814 - 0s - loss: 1.1043 - val_loss: 1.0163\n",
      "Epoch 46/1000\n",
      "6814/6814 - 0s - loss: 1.0525 - val_loss: 0.9778\n",
      "Epoch 47/1000\n",
      "6814/6814 - 0s - loss: 1.0463 - val_loss: 1.0178\n",
      "Epoch 48/1000\n",
      "6814/6814 - 0s - loss: 1.0148 - val_loss: 0.9546\n",
      "Epoch 49/1000\n",
      "6814/6814 - 0s - loss: 1.0003 - val_loss: 0.9379\n",
      "Epoch 50/1000\n",
      "6814/6814 - 0s - loss: 0.9734 - val_loss: 0.9619\n",
      "Epoch 51/1000\n",
      "6814/6814 - 0s - loss: 0.9296 - val_loss: 0.8720\n",
      "Epoch 52/1000\n",
      "6814/6814 - 0s - loss: 0.8971 - val_loss: 0.8520\n",
      "Epoch 53/1000\n",
      "6814/6814 - 0s - loss: 0.8788 - val_loss: 0.8086\n",
      "Epoch 54/1000\n",
      "6814/6814 - 0s - loss: 0.8079 - val_loss: 0.7547\n",
      "Epoch 55/1000\n",
      "6814/6814 - 0s - loss: 0.7650 - val_loss: 0.8348\n",
      "Epoch 56/1000\n",
      "6814/6814 - 0s - loss: 0.8327 - val_loss: 0.7148\n",
      "Epoch 57/1000\n",
      "6814/6814 - 0s - loss: 0.7392 - val_loss: 0.7505\n",
      "Epoch 58/1000\n",
      "6814/6814 - 0s - loss: 0.7425 - val_loss: 0.8417\n",
      "Epoch 59/1000\n",
      "6814/6814 - 0s - loss: 0.7587 - val_loss: 0.8671\n",
      "Epoch 60/1000\n",
      "6814/6814 - 0s - loss: 0.7837 - val_loss: 0.8653\n",
      "Epoch 61/1000\n",
      "6814/6814 - 0s - loss: 0.7091 - val_loss: 0.7054\n",
      "Epoch 62/1000\n",
      "6814/6814 - 0s - loss: 0.7091 - val_loss: 0.7442\n",
      "Epoch 63/1000\n",
      "6814/6814 - 0s - loss: 0.6964 - val_loss: 0.6705\n",
      "Epoch 64/1000\n",
      "6814/6814 - 0s - loss: 0.6855 - val_loss: 0.6630\n",
      "Epoch 65/1000\n",
      "6814/6814 - 0s - loss: 0.6773 - val_loss: 0.8258\n",
      "Epoch 66/1000\n",
      "6814/6814 - 0s - loss: 0.6918 - val_loss: 0.6594\n",
      "Epoch 67/1000\n",
      "6814/6814 - 0s - loss: 0.6766 - val_loss: 0.7784\n",
      "Epoch 68/1000\n",
      "6814/6814 - 0s - loss: 0.6731 - val_loss: 0.6812\n",
      "Epoch 69/1000\n",
      "6814/6814 - 0s - loss: 0.6887 - val_loss: 0.6899\n",
      "Epoch 70/1000\n",
      "6814/6814 - 0s - loss: 0.6894 - val_loss: 0.6944\n",
      "Epoch 71/1000\n",
      "6814/6814 - 0s - loss: 0.6751 - val_loss: 0.6717\n",
      "Epoch 72/1000\n",
      "6814/6814 - 0s - loss: 0.6999 - val_loss: 0.6582\n",
      "Epoch 73/1000\n",
      "6814/6814 - 0s - loss: 0.6579 - val_loss: 0.6518\n",
      "Epoch 74/1000\n",
      "6814/6814 - 0s - loss: 0.6578 - val_loss: 0.8042\n",
      "Epoch 75/1000\n",
      "6814/6814 - 0s - loss: 0.6964 - val_loss: 0.6438\n",
      "Epoch 76/1000\n",
      "6814/6814 - 0s - loss: 0.6599 - val_loss: 0.7094\n",
      "Epoch 77/1000\n",
      "6814/6814 - 0s - loss: 0.6788 - val_loss: 0.6582\n",
      "Epoch 78/1000\n",
      "6814/6814 - 0s - loss: 0.6353 - val_loss: 0.7046\n",
      "Epoch 79/1000\n",
      "6814/6814 - 0s - loss: 0.6541 - val_loss: 0.8952\n",
      "Epoch 80/1000\n",
      "6814/6814 - 0s - loss: 0.6828 - val_loss: 0.6411\n",
      "Epoch 81/1000\n",
      "6814/6814 - 0s - loss: 0.6441 - val_loss: 0.6572\n",
      "Epoch 82/1000\n",
      "6814/6814 - 0s - loss: 0.6546 - val_loss: 0.7726\n",
      "Epoch 83/1000\n",
      "6814/6814 - 0s - loss: 0.6740 - val_loss: 0.6467\n",
      "Epoch 84/1000\n",
      "6814/6814 - 0s - loss: 0.6237 - val_loss: 0.6382\n",
      "Epoch 85/1000\n",
      "6814/6814 - 0s - loss: 0.6279 - val_loss: 0.6353\n",
      "Epoch 86/1000\n",
      "6814/6814 - 0s - loss: 0.6349 - val_loss: 0.6379\n",
      "Epoch 87/1000\n",
      "6814/6814 - 0s - loss: 0.6418 - val_loss: 0.6425\n",
      "Epoch 88/1000\n",
      "6814/6814 - 0s - loss: 0.6424 - val_loss: 0.6428\n",
      "Epoch 89/1000\n",
      "6814/6814 - 0s - loss: 0.6248 - val_loss: 0.6611\n",
      "Epoch 90/1000\n",
      "6814/6814 - 0s - loss: 0.6375 - val_loss: 0.6397\n",
      "Epoch 91/1000\n",
      "6814/6814 - 0s - loss: 0.6562 - val_loss: 1.3872\n",
      "Epoch 92/1000\n",
      "6814/6814 - 0s - loss: 0.7271 - val_loss: 0.6688\n",
      "Epoch 00092: early stopping\n",
      "1\n",
      "Train on 6814 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6814/6814 - 0s - loss: 1222.5970 - val_loss: 481.5435\n",
      "Epoch 2/1000\n",
      "6814/6814 - 0s - loss: 146.1244 - val_loss: 1.9331\n",
      "Epoch 3/1000\n",
      "6814/6814 - 0s - loss: 2.2648 - val_loss: 1.8200\n",
      "Epoch 4/1000\n",
      "6814/6814 - 0s - loss: 1.8192 - val_loss: 1.7141\n",
      "Epoch 5/1000\n",
      "6814/6814 - 0s - loss: 1.7303 - val_loss: 1.6331\n",
      "Epoch 6/1000\n",
      "6814/6814 - 0s - loss: 1.6562 - val_loss: 1.5713\n",
      "Epoch 7/1000\n",
      "6814/6814 - 0s - loss: 1.6014 - val_loss: 1.5201\n",
      "Epoch 8/1000\n",
      "6814/6814 - 0s - loss: 1.5609 - val_loss: 1.4828\n",
      "Epoch 9/1000\n",
      "6814/6814 - 0s - loss: 1.5303 - val_loss: 1.4617\n",
      "Epoch 10/1000\n",
      "6814/6814 - 0s - loss: 1.5059 - val_loss: 1.4413\n",
      "Epoch 11/1000\n",
      "6814/6814 - 0s - loss: 1.4919 - val_loss: 1.4298\n",
      "Epoch 12/1000\n",
      "6814/6814 - 0s - loss: 1.4805 - val_loss: 1.4179\n",
      "Epoch 13/1000\n",
      "6814/6814 - 0s - loss: 1.4737 - val_loss: 1.4110\n",
      "Epoch 14/1000\n",
      "6814/6814 - 0s - loss: 1.4674 - val_loss: 1.4073\n",
      "Epoch 15/1000\n",
      "6814/6814 - 0s - loss: 1.4617 - val_loss: 1.4022\n",
      "Epoch 16/1000\n",
      "6814/6814 - 0s - loss: 1.4603 - val_loss: 1.4004\n",
      "Epoch 17/1000\n",
      "6814/6814 - 0s - loss: 1.4542 - val_loss: 1.3943\n",
      "Epoch 18/1000\n",
      "6814/6814 - 0s - loss: 1.4511 - val_loss: 1.3920\n",
      "Epoch 19/1000\n",
      "6814/6814 - 0s - loss: 1.4501 - val_loss: 1.3873\n",
      "Epoch 20/1000\n",
      "6814/6814 - 0s - loss: 1.4436 - val_loss: 1.3840\n",
      "Epoch 21/1000\n",
      "6814/6814 - 0s - loss: 1.4375 - val_loss: 1.3824\n",
      "Epoch 22/1000\n",
      "6814/6814 - 0s - loss: 1.4359 - val_loss: 1.3719\n",
      "Epoch 23/1000\n",
      "6814/6814 - 0s - loss: 1.4029 - val_loss: 1.3317\n",
      "Epoch 24/1000\n",
      "6814/6814 - 0s - loss: 1.3695 - val_loss: 1.3047\n",
      "Epoch 25/1000\n",
      "6814/6814 - 0s - loss: 1.3600 - val_loss: 1.3043\n",
      "Epoch 26/1000\n",
      "6814/6814 - 0s - loss: 1.3548 - val_loss: 1.2965\n",
      "Epoch 27/1000\n",
      "6814/6814 - 0s - loss: 1.3553 - val_loss: 1.2997\n",
      "Epoch 28/1000\n",
      "6814/6814 - 0s - loss: 1.3487 - val_loss: 1.2890\n",
      "Epoch 29/1000\n",
      "6814/6814 - 0s - loss: 1.3445 - val_loss: 1.2868\n",
      "Epoch 30/1000\n",
      "6814/6814 - 0s - loss: 1.3461 - val_loss: 1.2877\n",
      "Epoch 31/1000\n",
      "6814/6814 - 0s - loss: 1.3432 - val_loss: 1.2798\n",
      "Epoch 32/1000\n",
      "6814/6814 - 0s - loss: 1.3349 - val_loss: 1.2744\n",
      "Epoch 33/1000\n",
      "6814/6814 - 0s - loss: 1.3320 - val_loss: 1.2711\n",
      "Epoch 34/1000\n",
      "6814/6814 - 0s - loss: 1.3277 - val_loss: 1.2665\n",
      "Epoch 35/1000\n",
      "6814/6814 - 0s - loss: 1.3219 - val_loss: 1.2664\n",
      "Epoch 36/1000\n",
      "6814/6814 - 0s - loss: 1.3269 - val_loss: 1.2679\n",
      "Epoch 37/1000\n",
      "6814/6814 - 0s - loss: 1.3258 - val_loss: 1.2542\n",
      "Epoch 38/1000\n",
      "6814/6814 - 0s - loss: 1.3172 - val_loss: 1.2515\n",
      "Epoch 39/1000\n",
      "6814/6814 - 0s - loss: 1.3086 - val_loss: 1.2616\n",
      "Epoch 40/1000\n",
      "6814/6814 - 0s - loss: 1.3051 - val_loss: 1.2426\n",
      "Epoch 41/1000\n",
      "6814/6814 - 0s - loss: 1.2969 - val_loss: 1.2380\n",
      "Epoch 42/1000\n",
      "6814/6814 - 0s - loss: 1.2943 - val_loss: 1.2481\n",
      "Epoch 43/1000\n",
      "6814/6814 - 0s - loss: 1.2914 - val_loss: 1.2284\n",
      "Epoch 44/1000\n",
      "6814/6814 - 0s - loss: 1.2814 - val_loss: 1.2265\n",
      "Epoch 45/1000\n",
      "6814/6814 - 0s - loss: 1.2801 - val_loss: 1.2200\n",
      "Epoch 46/1000\n",
      "6814/6814 - 0s - loss: 1.2746 - val_loss: 1.2221\n",
      "Epoch 47/1000\n",
      "6814/6814 - 0s - loss: 1.2759 - val_loss: 1.2248\n",
      "Epoch 48/1000\n",
      "6814/6814 - 0s - loss: 1.2679 - val_loss: 1.2292\n",
      "Epoch 49/1000\n",
      "6814/6814 - 0s - loss: 1.2590 - val_loss: 1.1973\n",
      "Epoch 50/1000\n",
      "6814/6814 - 0s - loss: 1.2532 - val_loss: 1.1929\n",
      "Epoch 51/1000\n",
      "6814/6814 - 0s - loss: 1.2542 - val_loss: 1.1846\n",
      "Epoch 52/1000\n",
      "6814/6814 - 0s - loss: 1.2328 - val_loss: 1.1758\n",
      "Epoch 53/1000\n",
      "6814/6814 - 0s - loss: 1.2282 - val_loss: 1.1771\n",
      "Epoch 54/1000\n",
      "6814/6814 - 0s - loss: 1.2275 - val_loss: 1.1617\n",
      "Epoch 55/1000\n",
      "6814/6814 - 0s - loss: 1.2107 - val_loss: 1.1519\n",
      "Epoch 56/1000\n",
      "6814/6814 - 0s - loss: 1.2088 - val_loss: 1.1723\n",
      "Epoch 57/1000\n",
      "6814/6814 - 0s - loss: 1.1979 - val_loss: 1.1389\n",
      "Epoch 58/1000\n",
      "6814/6814 - 0s - loss: 1.1943 - val_loss: 1.1345\n",
      "Epoch 59/1000\n",
      "6814/6814 - 0s - loss: 1.1864 - val_loss: 1.1297\n",
      "Epoch 60/1000\n",
      "6814/6814 - 0s - loss: 1.1759 - val_loss: 1.1184\n",
      "Epoch 61/1000\n",
      "6814/6814 - 0s - loss: 1.1701 - val_loss: 1.1217\n",
      "Epoch 62/1000\n",
      "6814/6814 - 0s - loss: 1.1649 - val_loss: 1.1046\n",
      "Epoch 63/1000\n",
      "6814/6814 - 0s - loss: 1.1760 - val_loss: 1.1223\n",
      "Epoch 64/1000\n",
      "6814/6814 - 0s - loss: 1.1527 - val_loss: 1.0967\n",
      "Epoch 65/1000\n",
      "6814/6814 - 0s - loss: 1.1440 - val_loss: 1.0831\n",
      "Epoch 66/1000\n",
      "6814/6814 - 0s - loss: 1.1423 - val_loss: 1.0830\n",
      "Epoch 67/1000\n",
      "6814/6814 - 0s - loss: 1.1339 - val_loss: 1.0904\n",
      "Epoch 68/1000\n",
      "6814/6814 - 0s - loss: 1.1174 - val_loss: 1.0727\n",
      "Epoch 69/1000\n",
      "6814/6814 - 0s - loss: 1.1109 - val_loss: 1.0562\n",
      "Epoch 70/1000\n",
      "6814/6814 - 0s - loss: 1.0986 - val_loss: 1.0424\n",
      "Epoch 71/1000\n",
      "6814/6814 - 0s - loss: 1.0907 - val_loss: 1.0359\n",
      "Epoch 72/1000\n",
      "6814/6814 - 0s - loss: 1.0934 - val_loss: 1.0262\n",
      "Epoch 73/1000\n",
      "6814/6814 - 0s - loss: 1.0805 - val_loss: 1.0182\n",
      "Epoch 74/1000\n",
      "6814/6814 - 0s - loss: 1.0628 - val_loss: 1.0133\n",
      "Epoch 75/1000\n",
      "6814/6814 - 0s - loss: 1.0632 - val_loss: 1.0483\n",
      "Epoch 76/1000\n",
      "6814/6814 - 0s - loss: 1.0538 - val_loss: 0.9901\n",
      "Epoch 77/1000\n",
      "6814/6814 - 0s - loss: 1.0367 - val_loss: 0.9810\n",
      "Epoch 78/1000\n",
      "6814/6814 - 0s - loss: 1.0251 - val_loss: 0.9943\n",
      "Epoch 79/1000\n",
      "6814/6814 - 0s - loss: 1.0387 - val_loss: 0.9861\n",
      "Epoch 80/1000\n",
      "6814/6814 - 0s - loss: 1.0166 - val_loss: 0.9580\n",
      "Epoch 81/1000\n",
      "6814/6814 - 0s - loss: 0.9944 - val_loss: 0.9452\n",
      "Epoch 82/1000\n",
      "6814/6814 - 0s - loss: 0.9985 - val_loss: 0.9521\n",
      "Epoch 83/1000\n",
      "6814/6814 - 0s - loss: 0.9758 - val_loss: 0.9356\n",
      "Epoch 84/1000\n",
      "6814/6814 - 0s - loss: 0.9683 - val_loss: 0.9127\n",
      "Epoch 85/1000\n",
      "6814/6814 - 0s - loss: 0.9538 - val_loss: 0.9169\n",
      "Epoch 86/1000\n",
      "6814/6814 - 0s - loss: 0.9440 - val_loss: 0.9023\n",
      "Epoch 87/1000\n",
      "6814/6814 - 0s - loss: 0.9566 - val_loss: 0.8805\n",
      "Epoch 88/1000\n",
      "6814/6814 - 0s - loss: 0.9220 - val_loss: 0.9117\n",
      "Epoch 89/1000\n",
      "6814/6814 - 0s - loss: 0.9552 - val_loss: 0.8807\n",
      "Epoch 90/1000\n",
      "6814/6814 - 0s - loss: 0.9416 - val_loss: 0.9580\n",
      "Epoch 91/1000\n",
      "6814/6814 - 0s - loss: 0.8947 - val_loss: 0.8537\n",
      "Epoch 92/1000\n",
      "6814/6814 - 0s - loss: 0.8858 - val_loss: 0.8739\n",
      "Epoch 93/1000\n",
      "6814/6814 - 0s - loss: 0.9107 - val_loss: 0.8296\n",
      "Epoch 94/1000\n",
      "6814/6814 - 0s - loss: 0.8463 - val_loss: 0.8158\n",
      "Epoch 95/1000\n",
      "6814/6814 - 0s - loss: 0.8551 - val_loss: 0.7997\n",
      "Epoch 96/1000\n",
      "6814/6814 - 0s - loss: 0.8421 - val_loss: 0.7981\n",
      "Epoch 97/1000\n",
      "6814/6814 - 0s - loss: 0.8634 - val_loss: 0.7811\n",
      "Epoch 98/1000\n",
      "6814/6814 - 0s - loss: 0.8386 - val_loss: 0.7724\n",
      "Epoch 99/1000\n",
      "6814/6814 - 0s - loss: 0.8349 - val_loss: 0.7648\n",
      "Epoch 100/1000\n",
      "6814/6814 - 0s - loss: 0.7903 - val_loss: 0.7671\n",
      "Epoch 101/1000\n",
      "6814/6814 - 0s - loss: 0.8272 - val_loss: 0.7998\n",
      "Epoch 102/1000\n",
      "6814/6814 - 0s - loss: 0.8079 - val_loss: 0.7630\n",
      "Epoch 103/1000\n",
      "6814/6814 - 0s - loss: 0.7762 - val_loss: 0.7680\n",
      "Epoch 104/1000\n",
      "6814/6814 - 0s - loss: 0.8064 - val_loss: 0.8977\n",
      "Epoch 105/1000\n",
      "6814/6814 - 0s - loss: 0.7751 - val_loss: 0.7394\n",
      "Epoch 106/1000\n",
      "6814/6814 - 0s - loss: 0.7483 - val_loss: 0.7129\n",
      "Epoch 107/1000\n",
      "6814/6814 - 0s - loss: 0.7295 - val_loss: 0.7427\n",
      "Epoch 108/1000\n",
      "6814/6814 - 0s - loss: 0.7320 - val_loss: 0.7489\n",
      "Epoch 109/1000\n",
      "6814/6814 - 0s - loss: 0.7129 - val_loss: 0.7554\n",
      "Epoch 110/1000\n",
      "6814/6814 - 0s - loss: 0.7291 - val_loss: 0.7274\n",
      "Epoch 111/1000\n",
      "6814/6814 - 0s - loss: 0.7070 - val_loss: 0.6835\n",
      "Epoch 112/1000\n",
      "6814/6814 - 0s - loss: 0.6902 - val_loss: 0.7078\n",
      "Epoch 113/1000\n",
      "6814/6814 - 0s - loss: 0.6747 - val_loss: 0.7288\n",
      "Epoch 114/1000\n",
      "6814/6814 - 0s - loss: 0.6701 - val_loss: 0.6503\n",
      "Epoch 115/1000\n",
      "6814/6814 - 0s - loss: 0.6665 - val_loss: 0.6660\n",
      "Epoch 116/1000\n",
      "6814/6814 - 0s - loss: 0.6612 - val_loss: 0.6644\n",
      "Epoch 117/1000\n",
      "6814/6814 - 0s - loss: 0.6623 - val_loss: 0.6501\n",
      "Epoch 118/1000\n",
      "6814/6814 - 0s - loss: 0.6510 - val_loss: 0.6509\n",
      "Epoch 119/1000\n",
      "6814/6814 - 0s - loss: 0.6775 - val_loss: 0.6675\n",
      "Epoch 120/1000\n",
      "6814/6814 - 0s - loss: 0.7137 - val_loss: 0.6523\n",
      "Epoch 121/1000\n",
      "6814/6814 - 0s - loss: 0.7364 - val_loss: 0.6563\n",
      "Epoch 00121: early stopping\n",
      "2\n",
      "Train on 6814 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6814/6814 - 0s - loss: 750.7229 - val_loss: 2.6936\n",
      "Epoch 2/1000\n",
      "6814/6814 - 0s - loss: 2.8329 - val_loss: 1.5687\n",
      "Epoch 3/1000\n",
      "6814/6814 - 0s - loss: 1.4960 - val_loss: 1.3632\n",
      "Epoch 4/1000\n",
      "6814/6814 - 0s - loss: 1.3447 - val_loss: 1.2573\n",
      "Epoch 5/1000\n",
      "6814/6814 - 0s - loss: 1.2688 - val_loss: 1.2046\n",
      "Epoch 6/1000\n",
      "6814/6814 - 0s - loss: 1.2316 - val_loss: 1.1759\n",
      "Epoch 7/1000\n",
      "6814/6814 - 0s - loss: 1.2135 - val_loss: 1.1642\n",
      "Epoch 8/1000\n",
      "6814/6814 - 0s - loss: 1.2037 - val_loss: 1.1570\n",
      "Epoch 9/1000\n",
      "6814/6814 - 0s - loss: 1.1993 - val_loss: 1.1475\n",
      "Epoch 10/1000\n",
      "6814/6814 - 0s - loss: 1.1890 - val_loss: 1.1417\n",
      "Epoch 11/1000\n",
      "6814/6814 - 0s - loss: 1.1826 - val_loss: 1.1358\n",
      "Epoch 12/1000\n",
      "6814/6814 - 0s - loss: 1.1815 - val_loss: 1.1472\n",
      "Epoch 13/1000\n",
      "6814/6814 - 0s - loss: 1.1731 - val_loss: 1.1266\n",
      "Epoch 14/1000\n",
      "6814/6814 - 0s - loss: 1.1675 - val_loss: 1.1180\n",
      "Epoch 15/1000\n",
      "6814/6814 - 0s - loss: 1.1626 - val_loss: 1.1169\n",
      "Epoch 16/1000\n",
      "6814/6814 - 0s - loss: 1.1627 - val_loss: 1.1092\n",
      "Epoch 17/1000\n",
      "6814/6814 - 0s - loss: 1.1434 - val_loss: 1.0990\n",
      "Epoch 18/1000\n",
      "6814/6814 - 0s - loss: 1.1377 - val_loss: 1.0927\n",
      "Epoch 19/1000\n",
      "6814/6814 - 0s - loss: 1.1297 - val_loss: 1.0967\n",
      "Epoch 20/1000\n",
      "6814/6814 - 0s - loss: 1.1136 - val_loss: 1.0276\n",
      "Epoch 21/1000\n",
      "6814/6814 - 0s - loss: 1.0514 - val_loss: 0.9801\n",
      "Epoch 22/1000\n",
      "6814/6814 - 0s - loss: 1.0135 - val_loss: 0.9472\n",
      "Epoch 23/1000\n",
      "6814/6814 - 0s - loss: 0.9804 - val_loss: 0.9833\n",
      "Epoch 24/1000\n",
      "6814/6814 - 0s - loss: 0.9615 - val_loss: 0.9620\n",
      "Epoch 25/1000\n",
      "6814/6814 - 0s - loss: 0.9249 - val_loss: 0.8688\n",
      "Epoch 26/1000\n",
      "6814/6814 - 0s - loss: 0.9041 - val_loss: 0.8926\n",
      "Epoch 27/1000\n",
      "6814/6814 - 0s - loss: 0.8644 - val_loss: 0.8276\n",
      "Epoch 28/1000\n",
      "6814/6814 - 0s - loss: 0.8532 - val_loss: 0.8049\n",
      "Epoch 29/1000\n",
      "6814/6814 - 0s - loss: 0.8274 - val_loss: 0.9844\n",
      "Epoch 30/1000\n",
      "6814/6814 - 0s - loss: 0.8162 - val_loss: 0.8076\n",
      "Epoch 31/1000\n",
      "6814/6814 - 0s - loss: 0.8093 - val_loss: 0.7869\n",
      "Epoch 32/1000\n",
      "6814/6814 - 0s - loss: 0.7813 - val_loss: 0.7712\n",
      "Epoch 33/1000\n",
      "6814/6814 - 0s - loss: 0.7654 - val_loss: 0.7606\n",
      "Epoch 34/1000\n",
      "6814/6814 - 0s - loss: 0.7482 - val_loss: 0.7545\n",
      "Epoch 35/1000\n",
      "6814/6814 - 0s - loss: 0.7483 - val_loss: 0.7503\n",
      "Epoch 36/1000\n",
      "6814/6814 - 0s - loss: 0.7438 - val_loss: 0.7413\n",
      "Epoch 37/1000\n",
      "6814/6814 - 0s - loss: 0.7356 - val_loss: 0.7686\n",
      "Epoch 38/1000\n",
      "6814/6814 - 0s - loss: 0.7523 - val_loss: 0.7593\n",
      "Epoch 39/1000\n",
      "6814/6814 - 0s - loss: 0.7182 - val_loss: 0.7391\n",
      "Epoch 40/1000\n",
      "6814/6814 - 0s - loss: 0.7217 - val_loss: 0.7289\n",
      "Epoch 41/1000\n",
      "6814/6814 - 0s - loss: 0.7108 - val_loss: 0.7645\n",
      "Epoch 42/1000\n",
      "6814/6814 - 0s - loss: 0.7081 - val_loss: 0.7731\n",
      "Epoch 43/1000\n",
      "6814/6814 - 0s - loss: 0.7018 - val_loss: 0.7343\n",
      "Epoch 44/1000\n",
      "6814/6814 - 0s - loss: 0.6869 - val_loss: 0.7515\n",
      "Epoch 45/1000\n",
      "6814/6814 - 0s - loss: 0.7094 - val_loss: 0.7180\n",
      "Epoch 46/1000\n",
      "6814/6814 - 0s - loss: 0.6902 - val_loss: 0.7129\n",
      "Epoch 47/1000\n",
      "6814/6814 - 0s - loss: 0.6831 - val_loss: 0.7143\n",
      "Epoch 48/1000\n",
      "6814/6814 - 0s - loss: 0.7073 - val_loss: 0.7960\n",
      "Epoch 49/1000\n",
      "6814/6814 - 0s - loss: 0.6789 - val_loss: 0.7322\n",
      "Epoch 50/1000\n",
      "6814/6814 - 0s - loss: 0.6781 - val_loss: 0.7247\n",
      "Epoch 51/1000\n",
      "6814/6814 - 0s - loss: 0.6979 - val_loss: 0.7354\n",
      "Epoch 52/1000\n",
      "6814/6814 - 0s - loss: 0.7040 - val_loss: 0.7098\n",
      "Epoch 53/1000\n",
      "6814/6814 - 0s - loss: 0.7038 - val_loss: 0.7086\n",
      "Epoch 54/1000\n",
      "6814/6814 - 0s - loss: 0.6923 - val_loss: 0.7119\n",
      "Epoch 55/1000\n",
      "6814/6814 - 0s - loss: 0.6656 - val_loss: 0.7183\n",
      "Epoch 56/1000\n",
      "6814/6814 - 0s - loss: 0.6718 - val_loss: 0.7060\n",
      "Epoch 57/1000\n",
      "6814/6814 - 0s - loss: 0.6737 - val_loss: 0.7046\n",
      "Epoch 58/1000\n",
      "6814/6814 - 0s - loss: 0.6900 - val_loss: 0.9058\n",
      "Epoch 59/1000\n",
      "6814/6814 - 0s - loss: 0.6957 - val_loss: 0.7046\n",
      "Epoch 60/1000\n",
      "6814/6814 - 0s - loss: 0.6615 - val_loss: 0.7032\n",
      "Epoch 61/1000\n",
      "6814/6814 - 0s - loss: 0.6539 - val_loss: 0.7038\n",
      "Epoch 62/1000\n",
      "6814/6814 - 0s - loss: 0.6905 - val_loss: 0.7582\n",
      "Epoch 63/1000\n",
      "6814/6814 - 0s - loss: 0.6686 - val_loss: 0.6985\n",
      "Epoch 64/1000\n",
      "6814/6814 - 0s - loss: 0.6566 - val_loss: 0.7160\n",
      "Epoch 65/1000\n",
      "6814/6814 - 0s - loss: 0.6631 - val_loss: 0.7374\n",
      "Epoch 66/1000\n",
      "6814/6814 - 0s - loss: 0.6614 - val_loss: 0.6988\n",
      "Epoch 67/1000\n",
      "6814/6814 - 0s - loss: 0.6778 - val_loss: 0.6984\n",
      "Epoch 68/1000\n",
      "6814/6814 - 0s - loss: 0.6598 - val_loss: 0.8729\n",
      "Epoch 69/1000\n",
      "6814/6814 - 0s - loss: 0.6782 - val_loss: 0.6941\n",
      "Epoch 70/1000\n",
      "6814/6814 - 0s - loss: 0.6557 - val_loss: 0.6898\n",
      "Epoch 71/1000\n",
      "6814/6814 - 0s - loss: 0.6662 - val_loss: 0.6955\n",
      "Epoch 72/1000\n",
      "6814/6814 - 0s - loss: 0.6556 - val_loss: 0.7752\n",
      "Epoch 73/1000\n",
      "6814/6814 - 0s - loss: 0.6675 - val_loss: 0.6902\n",
      "Epoch 74/1000\n",
      "6814/6814 - 0s - loss: 0.6565 - val_loss: 0.7006\n",
      "Epoch 75/1000\n",
      "6814/6814 - 0s - loss: 0.6561 - val_loss: 0.6843\n",
      "Epoch 76/1000\n",
      "6814/6814 - 0s - loss: 0.6536 - val_loss: 0.7007\n",
      "Epoch 77/1000\n",
      "6814/6814 - 0s - loss: 0.6508 - val_loss: 0.7290\n",
      "Epoch 78/1000\n",
      "6814/6814 - 0s - loss: 0.6687 - val_loss: 0.7156\n",
      "Epoch 79/1000\n",
      "6814/6814 - 0s - loss: 0.6487 - val_loss: 0.6984\n",
      "Epoch 80/1000\n",
      "6814/6814 - 0s - loss: 0.6542 - val_loss: 0.6826\n",
      "Epoch 81/1000\n",
      "6814/6814 - 0s - loss: 0.6565 - val_loss: 0.6838\n",
      "Epoch 82/1000\n",
      "6814/6814 - 0s - loss: 0.6524 - val_loss: 0.6997\n",
      "Epoch 83/1000\n",
      "6814/6814 - 0s - loss: 0.6502 - val_loss: 0.7270\n",
      "Epoch 84/1000\n",
      "6814/6814 - 0s - loss: 0.6431 - val_loss: 0.7230\n",
      "Epoch 85/1000\n",
      "6814/6814 - 0s - loss: 0.6636 - val_loss: 0.7302\n",
      "Epoch 86/1000\n",
      "6814/6814 - 0s - loss: 0.6369 - val_loss: 0.6788\n",
      "Epoch 87/1000\n",
      "6814/6814 - 0s - loss: 0.6436 - val_loss: 0.7119\n",
      "Epoch 88/1000\n",
      "6814/6814 - 0s - loss: 0.6450 - val_loss: 0.6746\n",
      "Epoch 89/1000\n",
      "6814/6814 - 0s - loss: 0.6442 - val_loss: 0.6759\n",
      "Epoch 90/1000\n",
      "6814/6814 - 0s - loss: 0.7010 - val_loss: 0.8977\n",
      "Epoch 91/1000\n",
      "6814/6814 - 0s - loss: 0.6624 - val_loss: 0.6922\n",
      "Epoch 92/1000\n",
      "6814/6814 - 0s - loss: 0.6314 - val_loss: 0.6682\n",
      "Epoch 93/1000\n",
      "6814/6814 - 0s - loss: 0.6362 - val_loss: 0.7498\n",
      "Epoch 94/1000\n",
      "6814/6814 - 0s - loss: 0.6678 - val_loss: 0.8829\n",
      "Epoch 95/1000\n",
      "6814/6814 - 0s - loss: 0.6618 - val_loss: 0.6687\n",
      "Epoch 96/1000\n",
      "6814/6814 - 0s - loss: 0.6543 - val_loss: 0.6796\n",
      "Epoch 97/1000\n",
      "6814/6814 - 0s - loss: 0.6685 - val_loss: 0.7267\n",
      "Epoch 98/1000\n",
      "6814/6814 - 0s - loss: 0.6312 - val_loss: 0.7160\n",
      "Epoch 99/1000\n",
      "6814/6814 - 0s - loss: 0.6269 - val_loss: 0.7598\n",
      "Epoch 00099: early stopping\n",
      "3\n",
      "Train on 6814 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6814/6814 - 0s - loss: 11.4817 - val_loss: 1.5070\n",
      "Epoch 2/1000\n",
      "6814/6814 - 0s - loss: 1.4545 - val_loss: 1.3618\n",
      "Epoch 3/1000\n",
      "6814/6814 - 0s - loss: 1.3968 - val_loss: 1.3372\n",
      "Epoch 4/1000\n",
      "6814/6814 - 0s - loss: 1.3732 - val_loss: 1.2962\n",
      "Epoch 5/1000\n",
      "6814/6814 - 0s - loss: 1.3367 - val_loss: 1.3106\n",
      "Epoch 6/1000\n",
      "6814/6814 - 0s - loss: 1.3034 - val_loss: 1.2444\n",
      "Epoch 7/1000\n",
      "6814/6814 - 0s - loss: 1.2644 - val_loss: 1.2084\n",
      "Epoch 8/1000\n",
      "6814/6814 - 0s - loss: 1.2480 - val_loss: 1.1822\n",
      "Epoch 9/1000\n",
      "6814/6814 - 0s - loss: 1.2105 - val_loss: 1.1493\n",
      "Epoch 10/1000\n",
      "6814/6814 - 0s - loss: 1.1809 - val_loss: 1.1194\n",
      "Epoch 11/1000\n",
      "6814/6814 - 0s - loss: 1.1461 - val_loss: 1.0868\n",
      "Epoch 12/1000\n",
      "6814/6814 - 0s - loss: 1.1027 - val_loss: 1.0536\n",
      "Epoch 13/1000\n",
      "6814/6814 - 0s - loss: 1.0874 - val_loss: 1.0479\n",
      "Epoch 14/1000\n",
      "6814/6814 - 0s - loss: 1.0455 - val_loss: 1.0546\n",
      "Epoch 15/1000\n",
      "6814/6814 - 0s - loss: 1.0024 - val_loss: 1.0257\n",
      "Epoch 16/1000\n",
      "6814/6814 - 0s - loss: 0.9344 - val_loss: 0.9323\n",
      "Epoch 17/1000\n",
      "6814/6814 - 0s - loss: 0.9049 - val_loss: 1.2222\n",
      "Epoch 18/1000\n",
      "6814/6814 - 0s - loss: 0.9133 - val_loss: 0.8107\n",
      "Epoch 19/1000\n",
      "6814/6814 - 0s - loss: 0.8001 - val_loss: 0.8396\n",
      "Epoch 20/1000\n",
      "6814/6814 - 0s - loss: 0.8176 - val_loss: 0.7833\n",
      "Epoch 21/1000\n",
      "6814/6814 - 0s - loss: 0.7784 - val_loss: 0.8350\n",
      "Epoch 22/1000\n",
      "6814/6814 - 0s - loss: 0.8351 - val_loss: 0.7923\n",
      "Epoch 23/1000\n",
      "6814/6814 - 0s - loss: 0.7900 - val_loss: 0.8499\n",
      "Epoch 24/1000\n",
      "6814/6814 - 0s - loss: 0.7591 - val_loss: 0.7703\n",
      "Epoch 25/1000\n",
      "6814/6814 - 0s - loss: 0.7622 - val_loss: 0.8235\n",
      "Epoch 26/1000\n",
      "6814/6814 - 0s - loss: 0.7606 - val_loss: 0.8594\n",
      "Epoch 27/1000\n",
      "6814/6814 - 0s - loss: 0.7796 - val_loss: 0.7639\n",
      "Epoch 28/1000\n",
      "6814/6814 - 0s - loss: 0.7342 - val_loss: 0.7546\n",
      "Epoch 29/1000\n",
      "6814/6814 - 0s - loss: 0.7461 - val_loss: 0.8191\n",
      "Epoch 30/1000\n",
      "6814/6814 - 0s - loss: 0.7241 - val_loss: 0.8066\n",
      "Epoch 31/1000\n",
      "6814/6814 - 0s - loss: 0.7683 - val_loss: 0.7476\n",
      "Epoch 32/1000\n",
      "6814/6814 - 0s - loss: 0.7553 - val_loss: 0.8384\n",
      "Epoch 33/1000\n",
      "6814/6814 - 0s - loss: 0.7457 - val_loss: 0.7590\n",
      "Epoch 34/1000\n",
      "6814/6814 - 0s - loss: 0.7585 - val_loss: 0.7321\n",
      "Epoch 35/1000\n",
      "6814/6814 - 0s - loss: 0.7443 - val_loss: 0.8439\n",
      "Epoch 36/1000\n",
      "6814/6814 - 0s - loss: 0.7689 - val_loss: 0.8064\n",
      "Epoch 37/1000\n",
      "6814/6814 - 0s - loss: 0.7388 - val_loss: 0.7172\n",
      "Epoch 38/1000\n",
      "6814/6814 - 0s - loss: 0.7033 - val_loss: 0.9108\n",
      "Epoch 39/1000\n",
      "6814/6814 - 0s - loss: 0.7132 - val_loss: 0.9417\n",
      "Epoch 40/1000\n",
      "6814/6814 - 0s - loss: 0.7488 - val_loss: 0.7595\n",
      "Epoch 41/1000\n",
      "6814/6814 - 0s - loss: 0.7044 - val_loss: 0.7259\n",
      "Epoch 42/1000\n",
      "6814/6814 - 0s - loss: 0.7107 - val_loss: 0.7635\n",
      "Epoch 43/1000\n",
      "6814/6814 - 0s - loss: 0.7132 - val_loss: 0.7157\n",
      "Epoch 44/1000\n",
      "6814/6814 - 0s - loss: 0.7024 - val_loss: 0.7050\n",
      "Epoch 45/1000\n",
      "6814/6814 - 0s - loss: 0.6841 - val_loss: 0.7405\n",
      "Epoch 46/1000\n",
      "6814/6814 - 0s - loss: 0.6858 - val_loss: 0.7184\n",
      "Epoch 47/1000\n",
      "6814/6814 - 0s - loss: 0.6868 - val_loss: 0.7057\n",
      "Epoch 48/1000\n",
      "6814/6814 - 0s - loss: 0.6661 - val_loss: 0.6919\n",
      "Epoch 49/1000\n",
      "6814/6814 - 0s - loss: 0.7402 - val_loss: 0.7282\n",
      "Epoch 50/1000\n",
      "6814/6814 - 0s - loss: 0.6764 - val_loss: 0.6857\n",
      "Epoch 51/1000\n",
      "6814/6814 - 0s - loss: 0.7377 - val_loss: 0.6766\n",
      "Epoch 52/1000\n",
      "6814/6814 - 0s - loss: 0.6891 - val_loss: 0.7031\n",
      "Epoch 53/1000\n",
      "6814/6814 - 0s - loss: 0.6619 - val_loss: 0.8801\n",
      "Epoch 54/1000\n",
      "6814/6814 - 0s - loss: 0.6767 - val_loss: 0.8709\n",
      "Epoch 55/1000\n",
      "6814/6814 - 0s - loss: 0.7067 - val_loss: 0.6805\n",
      "Epoch 56/1000\n",
      "6814/6814 - 0s - loss: 0.6608 - val_loss: 0.6730\n",
      "Epoch 57/1000\n",
      "6814/6814 - 0s - loss: 0.6873 - val_loss: 0.7922\n",
      "Epoch 58/1000\n",
      "6814/6814 - 0s - loss: 0.6586 - val_loss: 0.6756\n",
      "Epoch 59/1000\n",
      "6814/6814 - 0s - loss: 0.6967 - val_loss: 0.6662\n",
      "Epoch 60/1000\n",
      "6814/6814 - 0s - loss: 0.7209 - val_loss: 0.8409\n",
      "Epoch 61/1000\n",
      "6814/6814 - 0s - loss: 0.6920 - val_loss: 0.6690\n",
      "Epoch 62/1000\n",
      "6814/6814 - 0s - loss: 0.7127 - val_loss: 0.7026\n",
      "Epoch 63/1000\n",
      "6814/6814 - 0s - loss: 0.6737 - val_loss: 0.6741\n",
      "Epoch 64/1000\n",
      "6814/6814 - 0s - loss: 0.6928 - val_loss: 0.6587\n",
      "Epoch 65/1000\n",
      "6814/6814 - 0s - loss: 0.6572 - val_loss: 0.6690\n",
      "Epoch 66/1000\n",
      "6814/6814 - 0s - loss: 0.6514 - val_loss: 0.6886\n",
      "Epoch 67/1000\n",
      "6814/6814 - 0s - loss: 0.6710 - val_loss: 0.6755\n",
      "Epoch 68/1000\n",
      "6814/6814 - 0s - loss: 0.6392 - val_loss: 0.6816\n",
      "Epoch 69/1000\n",
      "6814/6814 - 0s - loss: 0.6952 - val_loss: 0.7318\n",
      "Epoch 70/1000\n",
      "6814/6814 - 0s - loss: 0.7025 - val_loss: 0.7117\n",
      "Epoch 71/1000\n",
      "6814/6814 - 0s - loss: 0.7134 - val_loss: 0.7366\n",
      "Epoch 00071: early stopping\n",
      "4\n",
      "Train on 6814 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6814/6814 - 0s - loss: 372.9234 - val_loss: 10.7948\n",
      "Epoch 2/1000\n",
      "6814/6814 - 0s - loss: 2.6332 - val_loss: 1.5727\n",
      "Epoch 3/1000\n",
      "6814/6814 - 0s - loss: 1.4120 - val_loss: 1.2487\n",
      "Epoch 4/1000\n",
      "6814/6814 - 0s - loss: 1.2329 - val_loss: 1.1622\n",
      "Epoch 5/1000\n",
      "6814/6814 - 0s - loss: 1.1969 - val_loss: 1.1471\n",
      "Epoch 6/1000\n",
      "6814/6814 - 0s - loss: 1.1869 - val_loss: 1.1674\n",
      "Epoch 7/1000\n",
      "6814/6814 - 0s - loss: 1.1794 - val_loss: 1.1376\n",
      "Epoch 8/1000\n",
      "6814/6814 - 0s - loss: 1.1674 - val_loss: 1.1185\n",
      "Epoch 9/1000\n",
      "6814/6814 - 0s - loss: 1.1543 - val_loss: 1.1070\n",
      "Epoch 10/1000\n",
      "6814/6814 - 0s - loss: 1.1425 - val_loss: 1.0874\n",
      "Epoch 11/1000\n",
      "6814/6814 - 0s - loss: 1.1324 - val_loss: 1.0910\n",
      "Epoch 12/1000\n",
      "6814/6814 - 0s - loss: 1.1140 - val_loss: 1.0640\n",
      "Epoch 13/1000\n",
      "6814/6814 - 0s - loss: 1.0975 - val_loss: 1.0557\n",
      "Epoch 14/1000\n",
      "6814/6814 - 0s - loss: 1.0865 - val_loss: 1.0610\n",
      "Epoch 15/1000\n",
      "6814/6814 - 0s - loss: 1.0819 - val_loss: 1.0411\n",
      "Epoch 16/1000\n",
      "6814/6814 - 0s - loss: 1.0701 - val_loss: 1.0263\n",
      "Epoch 17/1000\n",
      "6814/6814 - 0s - loss: 1.0669 - val_loss: 1.0158\n",
      "Epoch 18/1000\n",
      "6814/6814 - 0s - loss: 1.0494 - val_loss: 1.0059\n",
      "Epoch 19/1000\n",
      "6814/6814 - 0s - loss: 1.0405 - val_loss: 0.9978\n",
      "Epoch 20/1000\n",
      "6814/6814 - 0s - loss: 1.0333 - val_loss: 0.9891\n",
      "Epoch 21/1000\n",
      "6814/6814 - 0s - loss: 1.0209 - val_loss: 0.9822\n",
      "Epoch 22/1000\n",
      "6814/6814 - 0s - loss: 1.0129 - val_loss: 0.9731\n",
      "Epoch 23/1000\n",
      "6814/6814 - 0s - loss: 1.0024 - val_loss: 0.9671\n",
      "Epoch 24/1000\n",
      "6814/6814 - 0s - loss: 0.9947 - val_loss: 0.9558\n",
      "Epoch 25/1000\n",
      "6814/6814 - 0s - loss: 0.9849 - val_loss: 0.9500\n",
      "Epoch 26/1000\n",
      "6814/6814 - 0s - loss: 0.9773 - val_loss: 0.9515\n",
      "Epoch 27/1000\n",
      "6814/6814 - 0s - loss: 0.9737 - val_loss: 0.9397\n",
      "Epoch 28/1000\n",
      "6814/6814 - 0s - loss: 0.9708 - val_loss: 0.9326\n",
      "Epoch 29/1000\n",
      "6814/6814 - 0s - loss: 0.9553 - val_loss: 0.9367\n",
      "Epoch 30/1000\n",
      "6814/6814 - 0s - loss: 0.9501 - val_loss: 0.9171\n",
      "Epoch 31/1000\n",
      "6814/6814 - 0s - loss: 0.9438 - val_loss: 0.9276\n",
      "Epoch 32/1000\n",
      "6814/6814 - 0s - loss: 0.9342 - val_loss: 0.8978\n",
      "Epoch 33/1000\n",
      "6814/6814 - 0s - loss: 0.9184 - val_loss: 0.8859\n",
      "Epoch 34/1000\n",
      "6814/6814 - 0s - loss: 0.9089 - val_loss: 0.8802\n",
      "Epoch 35/1000\n",
      "6814/6814 - 0s - loss: 0.9079 - val_loss: 0.8796\n",
      "Epoch 36/1000\n",
      "6814/6814 - 0s - loss: 0.9016 - val_loss: 0.8867\n",
      "Epoch 37/1000\n",
      "6814/6814 - 0s - loss: 0.9098 - val_loss: 0.8866\n",
      "Epoch 38/1000\n",
      "6814/6814 - 0s - loss: 0.8806 - val_loss: 0.8495\n",
      "Epoch 39/1000\n",
      "6814/6814 - 0s - loss: 0.8788 - val_loss: 0.8717\n",
      "Epoch 40/1000\n",
      "6814/6814 - 0s - loss: 0.8663 - val_loss: 0.8629\n",
      "Epoch 41/1000\n",
      "6814/6814 - 0s - loss: 0.8572 - val_loss: 0.8716\n",
      "Epoch 42/1000\n",
      "6814/6814 - 0s - loss: 0.9087 - val_loss: 0.8187\n",
      "Epoch 43/1000\n",
      "6814/6814 - 0s - loss: 0.8594 - val_loss: 0.8142\n",
      "Epoch 44/1000\n",
      "6814/6814 - 0s - loss: 0.8336 - val_loss: 0.8039\n",
      "Epoch 45/1000\n",
      "6814/6814 - 0s - loss: 0.8571 - val_loss: 0.7969\n",
      "Epoch 46/1000\n",
      "6814/6814 - 0s - loss: 0.8225 - val_loss: 0.7933\n",
      "Epoch 47/1000\n",
      "6814/6814 - 0s - loss: 0.8180 - val_loss: 0.7960\n",
      "Epoch 48/1000\n",
      "6814/6814 - 0s - loss: 0.8071 - val_loss: 0.7978\n",
      "Epoch 49/1000\n",
      "6814/6814 - 0s - loss: 0.7999 - val_loss: 0.7956\n",
      "Epoch 50/1000\n",
      "6814/6814 - 0s - loss: 0.7963 - val_loss: 0.7686\n",
      "Epoch 51/1000\n",
      "6814/6814 - 0s - loss: 0.7807 - val_loss: 0.7606\n",
      "Epoch 52/1000\n",
      "6814/6814 - 0s - loss: 0.7882 - val_loss: 0.7555\n",
      "Epoch 53/1000\n",
      "6814/6814 - 0s - loss: 0.7657 - val_loss: 0.7612\n",
      "Epoch 54/1000\n",
      "6814/6814 - 0s - loss: 0.7604 - val_loss: 0.8352\n",
      "Epoch 55/1000\n",
      "6814/6814 - 0s - loss: 0.7746 - val_loss: 0.8440\n",
      "Epoch 56/1000\n",
      "6814/6814 - 0s - loss: 0.7597 - val_loss: 0.7431\n",
      "Epoch 57/1000\n",
      "6814/6814 - 0s - loss: 0.7490 - val_loss: 0.7437\n",
      "Epoch 58/1000\n",
      "6814/6814 - 0s - loss: 0.7596 - val_loss: 0.7566\n",
      "Epoch 59/1000\n",
      "6814/6814 - 0s - loss: 0.7295 - val_loss: 0.7261\n",
      "Epoch 60/1000\n",
      "6814/6814 - 0s - loss: 0.7382 - val_loss: 0.7451\n",
      "Epoch 61/1000\n",
      "6814/6814 - 0s - loss: 0.7770 - val_loss: 0.7185\n",
      "Epoch 62/1000\n",
      "6814/6814 - 0s - loss: 0.7325 - val_loss: 0.7285\n",
      "Epoch 63/1000\n",
      "6814/6814 - 0s - loss: 0.7352 - val_loss: 1.0563\n",
      "Epoch 64/1000\n",
      "6814/6814 - 0s - loss: 0.7322 - val_loss: 0.7117\n",
      "Epoch 65/1000\n",
      "6814/6814 - 0s - loss: 0.7265 - val_loss: 0.7366\n",
      "Epoch 66/1000\n",
      "6814/6814 - 0s - loss: 0.7229 - val_loss: 0.7465\n",
      "Epoch 67/1000\n",
      "6814/6814 - 0s - loss: 0.7163 - val_loss: 0.7087\n",
      "Epoch 68/1000\n",
      "6814/6814 - 0s - loss: 0.7349 - val_loss: 0.7020\n",
      "Epoch 69/1000\n",
      "6814/6814 - 0s - loss: 0.7036 - val_loss: 0.6962\n",
      "Epoch 70/1000\n",
      "6814/6814 - 0s - loss: 0.6933 - val_loss: 0.7057\n",
      "Epoch 71/1000\n",
      "6814/6814 - 0s - loss: 0.7110 - val_loss: 0.7751\n",
      "Epoch 72/1000\n",
      "6814/6814 - 0s - loss: 0.7253 - val_loss: 0.7432\n",
      "Epoch 73/1000\n",
      "6814/6814 - 0s - loss: 0.6991 - val_loss: 0.6973\n",
      "Epoch 74/1000\n",
      "6814/6814 - 0s - loss: 0.6844 - val_loss: 0.6955\n",
      "Epoch 75/1000\n",
      "6814/6814 - 0s - loss: 0.6758 - val_loss: 0.6874\n",
      "Epoch 76/1000\n",
      "6814/6814 - 0s - loss: 0.6864 - val_loss: 0.6830\n",
      "Epoch 77/1000\n",
      "6814/6814 - 0s - loss: 0.6931 - val_loss: 0.6941\n",
      "Epoch 78/1000\n",
      "6814/6814 - 0s - loss: 0.7209 - val_loss: 0.6850\n",
      "Epoch 79/1000\n",
      "6814/6814 - 0s - loss: 0.6687 - val_loss: 0.6754\n",
      "Epoch 80/1000\n",
      "6814/6814 - 0s - loss: 0.6767 - val_loss: 0.7389\n",
      "Epoch 81/1000\n",
      "6814/6814 - 0s - loss: 0.6705 - val_loss: 0.7229\n",
      "Epoch 82/1000\n",
      "6814/6814 - 0s - loss: 0.6724 - val_loss: 0.6939\n",
      "Epoch 83/1000\n",
      "6814/6814 - 0s - loss: 0.6644 - val_loss: 0.6716\n",
      "Epoch 84/1000\n",
      "6814/6814 - 0s - loss: 0.6547 - val_loss: 0.7022\n",
      "Epoch 85/1000\n",
      "6814/6814 - 0s - loss: 0.6553 - val_loss: 0.6941\n",
      "Epoch 86/1000\n",
      "6814/6814 - 0s - loss: 0.6701 - val_loss: 0.6604\n",
      "Epoch 87/1000\n",
      "6814/6814 - 0s - loss: 0.7177 - val_loss: 0.7263\n",
      "Epoch 88/1000\n",
      "6814/6814 - 0s - loss: 0.6481 - val_loss: 0.6613\n",
      "Epoch 89/1000\n",
      "6814/6814 - 0s - loss: 0.6545 - val_loss: 0.8129\n",
      "Epoch 90/1000\n",
      "6814/6814 - 0s - loss: 0.7084 - val_loss: 0.6688\n",
      "Epoch 91/1000\n",
      "6814/6814 - 0s - loss: 0.6826 - val_loss: 0.6815\n",
      "Epoch 92/1000\n",
      "6814/6814 - 0s - loss: 0.6436 - val_loss: 0.6547\n",
      "Epoch 93/1000\n",
      "6814/6814 - 0s - loss: 0.6460 - val_loss: 0.6488\n",
      "Epoch 94/1000\n",
      "6814/6814 - 0s - loss: 0.6788 - val_loss: 0.7028\n",
      "Epoch 95/1000\n",
      "6814/6814 - 0s - loss: 0.6637 - val_loss: 0.6665\n",
      "Epoch 96/1000\n",
      "6814/6814 - 0s - loss: 0.6396 - val_loss: 0.6882\n",
      "Epoch 97/1000\n",
      "6814/6814 - 0s - loss: 0.6498 - val_loss: 0.7213\n",
      "Epoch 98/1000\n",
      "6814/6814 - 0s - loss: 0.6945 - val_loss: 1.0411\n",
      "Epoch 99/1000\n",
      "6814/6814 - 0s - loss: 0.7048 - val_loss: 0.8192\n",
      "Epoch 100/1000\n",
      "6814/6814 - 0s - loss: 0.6374 - val_loss: 0.6764\n",
      "Epoch 00100: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n",
      "[[ 8.8213215]\n",
      " [39.5233   ]\n",
      " [40.446003 ]\n",
      " ...\n",
      " [55.60917  ]\n",
      " [35.05995  ]\n",
      " [40.01863  ]]\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=r\"C:\\Users\\siris\\OneDrive\\Desktop\\215\\mini-project2\\best_weights4.hdf5\", verbose=0, save_best_only=True)\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=7, verbose=1, mode='auto')\n",
    "     # save best model\n",
    "\n",
    "    # batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test), batch_size= 128, callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "print('Training finished...Loading the best model')  \n",
    "print()\n",
    "model.load_weights(r\"C:\\Users\\siris\\OneDrive\\Desktop\\215\\mini-project2\\best_weights4.hdf5\") # load weights from best model\n",
    "\n",
    "# Predict and measure RMSE\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "#pred = np.argmax(pred,axis=1) # raw probabilities to choose class (highest probability)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 0.7970456480979919\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test, sort=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
