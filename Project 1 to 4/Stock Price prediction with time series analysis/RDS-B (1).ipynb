{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "    \n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "    \n",
    "\n",
    "preprocess = True\n",
    "\n",
    "filename_read = os.path.join(r\"C:\\Users\\siris\\OneDrive\\Desktop\\215\\mini-project2\\RDS-B.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "df.drop('Adj Close', axis=1, inplace=True)\n",
    "if preprocess:\n",
    "    encode_numeric_zscore(df, 'Open')\n",
    "    encode_numeric_zscore(df, 'High')\n",
    "    encode_numeric_zscore(df, 'Low')\n",
    "    encode_numeric_zscore(df, 'Volume')\n",
    "\n",
    "    \n",
    "x,y = to_xy(df,'Close')\n",
    "\n",
    "y2=df.Close\n",
    "encode_numeric_zscore(df, 'Close')\n",
    "y2=y2.values.astype(np.float32)\n",
    "x=np.concatenate((x, y[:,None]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "last = y.shape[0]\n",
    "i = 0\n",
    "#X_Row = np.concatenate((x[i],y[i]), axis=None)\n",
    "X_Row = x[i]\n",
    "for j in range(1,10):\n",
    "    X_Row = np.concatenate((X_Row, x[i+j]), axis=None)\n",
    "X = X_Row\n",
    "Y = y[10]\n",
    "i = i + 1\n",
    "\n",
    "while i < (last-10):\n",
    "    X_Row = x[i]\n",
    "    for j in range(1,10):\n",
    "        X_Row = np.concatenate((X_Row, x[i+j]), axis=None)\n",
    "    X = np.vstack((X, X_Row))\n",
    "    Y = np.concatenate((Y, y[i+10]), axis=None)    \n",
    "    i = i + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X , Y , test_size=0.30, random_state=42)\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 6813 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6813/6813 - 0s - loss: 730.3175 - val_loss: 2.8261\n",
      "Epoch 2/1000\n",
      "6813/6813 - 0s - loss: 3.7774 - val_loss: 2.0468\n",
      "Epoch 3/1000\n",
      "6813/6813 - 0s - loss: 1.8134 - val_loss: 1.9071\n",
      "Epoch 4/1000\n",
      "6813/6813 - 0s - loss: 1.7128 - val_loss: 1.8622\n",
      "Epoch 5/1000\n",
      "6813/6813 - 0s - loss: 1.6788 - val_loss: 1.8314\n",
      "Epoch 6/1000\n",
      "6813/6813 - 0s - loss: 1.6572 - val_loss: 1.8033\n",
      "Epoch 7/1000\n",
      "6813/6813 - 0s - loss: 1.6192 - val_loss: 1.7881\n",
      "Epoch 8/1000\n",
      "6813/6813 - 0s - loss: 1.5898 - val_loss: 1.7572\n",
      "Epoch 9/1000\n",
      "6813/6813 - 0s - loss: 1.5626 - val_loss: 1.7336\n",
      "Epoch 10/1000\n",
      "6813/6813 - 0s - loss: 1.5419 - val_loss: 1.6843\n",
      "Epoch 11/1000\n",
      "6813/6813 - 0s - loss: 1.5004 - val_loss: 1.6425\n",
      "Epoch 12/1000\n",
      "6813/6813 - 0s - loss: 1.4703 - val_loss: 1.6111\n",
      "Epoch 13/1000\n",
      "6813/6813 - 0s - loss: 1.4399 - val_loss: 1.5829\n",
      "Epoch 14/1000\n",
      "6813/6813 - 0s - loss: 1.4209 - val_loss: 1.5734\n",
      "Epoch 15/1000\n",
      "6813/6813 - 0s - loss: 1.3851 - val_loss: 1.5183\n",
      "Epoch 16/1000\n",
      "6813/6813 - 0s - loss: 1.3619 - val_loss: 1.4953\n",
      "Epoch 17/1000\n",
      "6813/6813 - 0s - loss: 1.3403 - val_loss: 1.4582\n",
      "Epoch 18/1000\n",
      "6813/6813 - 0s - loss: 1.3167 - val_loss: 1.4673\n",
      "Epoch 19/1000\n",
      "6813/6813 - 0s - loss: 1.2865 - val_loss: 1.3890\n",
      "Epoch 20/1000\n",
      "6813/6813 - 0s - loss: 1.2542 - val_loss: 1.3724\n",
      "Epoch 21/1000\n",
      "6813/6813 - 0s - loss: 1.2218 - val_loss: 1.3338\n",
      "Epoch 22/1000\n",
      "6813/6813 - 0s - loss: 1.1908 - val_loss: 1.3274\n",
      "Epoch 23/1000\n",
      "6813/6813 - 0s - loss: 1.1776 - val_loss: 1.3152\n",
      "Epoch 24/1000\n",
      "6813/6813 - 0s - loss: 1.1534 - val_loss: 1.2136\n",
      "Epoch 25/1000\n",
      "6813/6813 - 0s - loss: 1.1187 - val_loss: 1.2045\n",
      "Epoch 26/1000\n",
      "6813/6813 - 0s - loss: 1.0852 - val_loss: 1.1648\n",
      "Epoch 27/1000\n",
      "6813/6813 - 0s - loss: 1.0800 - val_loss: 1.1652\n",
      "Epoch 28/1000\n",
      "6813/6813 - 0s - loss: 1.0565 - val_loss: 1.1118\n",
      "Epoch 29/1000\n",
      "6813/6813 - 0s - loss: 1.0347 - val_loss: 1.1089\n",
      "Epoch 30/1000\n",
      "6813/6813 - 0s - loss: 1.0271 - val_loss: 1.0865\n",
      "Epoch 31/1000\n",
      "6813/6813 - 0s - loss: 0.9989 - val_loss: 1.0431\n",
      "Epoch 32/1000\n",
      "6813/6813 - 0s - loss: 0.9952 - val_loss: 1.0503\n",
      "Epoch 33/1000\n",
      "6813/6813 - 0s - loss: 0.9708 - val_loss: 1.0847\n",
      "Epoch 34/1000\n",
      "6813/6813 - 0s - loss: 0.9566 - val_loss: 1.0076\n",
      "Epoch 35/1000\n",
      "6813/6813 - 0s - loss: 0.9402 - val_loss: 1.0458\n",
      "Epoch 36/1000\n",
      "6813/6813 - 0s - loss: 0.9695 - val_loss: 1.0327\n",
      "Epoch 37/1000\n",
      "6813/6813 - 0s - loss: 0.9173 - val_loss: 0.9729\n",
      "Epoch 38/1000\n",
      "6813/6813 - 0s - loss: 0.9249 - val_loss: 0.9796\n",
      "Epoch 39/1000\n",
      "6813/6813 - 0s - loss: 0.9015 - val_loss: 1.0140\n",
      "Epoch 40/1000\n",
      "6813/6813 - 0s - loss: 0.9093 - val_loss: 0.9250\n",
      "Epoch 41/1000\n",
      "6813/6813 - 0s - loss: 0.8928 - val_loss: 0.9183\n",
      "Epoch 42/1000\n",
      "6813/6813 - 0s - loss: 0.8700 - val_loss: 0.9462\n",
      "Epoch 43/1000\n",
      "6813/6813 - 0s - loss: 0.8992 - val_loss: 0.9700\n",
      "Epoch 44/1000\n",
      "6813/6813 - 0s - loss: 0.9235 - val_loss: 0.9448\n",
      "Epoch 45/1000\n",
      "6813/6813 - 0s - loss: 0.8593 - val_loss: 0.8839\n",
      "Epoch 46/1000\n",
      "6813/6813 - 0s - loss: 0.8435 - val_loss: 0.9038\n",
      "Epoch 47/1000\n",
      "6813/6813 - 0s - loss: 0.8847 - val_loss: 0.8824\n",
      "Epoch 48/1000\n",
      "6813/6813 - 0s - loss: 0.8683 - val_loss: 0.8696\n",
      "Epoch 49/1000\n",
      "6813/6813 - 0s - loss: 0.8307 - val_loss: 0.8619\n",
      "Epoch 50/1000\n",
      "6813/6813 - 0s - loss: 0.8422 - val_loss: 0.8488\n",
      "Epoch 51/1000\n",
      "6813/6813 - 0s - loss: 0.8165 - val_loss: 0.8718\n",
      "Epoch 52/1000\n",
      "6813/6813 - 0s - loss: 0.8260 - val_loss: 0.8721\n",
      "Epoch 53/1000\n",
      "6813/6813 - 0s - loss: 0.8122 - val_loss: 0.8346\n",
      "Epoch 54/1000\n",
      "6813/6813 - 0s - loss: 0.8034 - val_loss: 0.8605\n",
      "Epoch 55/1000\n",
      "6813/6813 - 0s - loss: 0.8360 - val_loss: 0.9829\n",
      "Epoch 56/1000\n",
      "6813/6813 - 0s - loss: 0.8466 - val_loss: 0.9428\n",
      "Epoch 57/1000\n",
      "6813/6813 - 0s - loss: 0.7956 - val_loss: 0.8572\n",
      "Epoch 58/1000\n",
      "6813/6813 - 0s - loss: 0.7995 - val_loss: 0.8914\n",
      "Epoch 59/1000\n",
      "6813/6813 - 0s - loss: 0.7882 - val_loss: 0.8239\n",
      "Epoch 60/1000\n",
      "6813/6813 - 0s - loss: 0.8187 - val_loss: 0.8010\n",
      "Epoch 61/1000\n",
      "6813/6813 - 0s - loss: 0.7825 - val_loss: 0.8678\n",
      "Epoch 62/1000\n",
      "6813/6813 - 0s - loss: 0.8028 - val_loss: 0.7980\n",
      "Epoch 63/1000\n",
      "6813/6813 - 0s - loss: 0.7775 - val_loss: 0.7872\n",
      "Epoch 64/1000\n",
      "6813/6813 - 0s - loss: 0.7700 - val_loss: 1.0630\n",
      "Epoch 65/1000\n",
      "6813/6813 - 0s - loss: 0.7737 - val_loss: 0.8084\n",
      "Epoch 66/1000\n",
      "6813/6813 - 0s - loss: 0.7739 - val_loss: 0.7745\n",
      "Epoch 67/1000\n",
      "6813/6813 - 0s - loss: 0.7508 - val_loss: 0.7864\n",
      "Epoch 68/1000\n",
      "6813/6813 - 0s - loss: 0.7454 - val_loss: 0.8463\n",
      "Epoch 69/1000\n",
      "6813/6813 - 0s - loss: 0.7719 - val_loss: 0.9355\n",
      "Epoch 70/1000\n",
      "6813/6813 - 0s - loss: 0.7630 - val_loss: 0.7543\n",
      "Epoch 71/1000\n",
      "6813/6813 - 0s - loss: 0.7232 - val_loss: 1.1041\n",
      "Epoch 72/1000\n",
      "6813/6813 - 0s - loss: 0.7586 - val_loss: 0.7504\n",
      "Epoch 73/1000\n",
      "6813/6813 - 0s - loss: 0.7253 - val_loss: 0.7578\n",
      "Epoch 74/1000\n",
      "6813/6813 - 0s - loss: 0.7246 - val_loss: 0.8133\n",
      "Epoch 75/1000\n",
      "6813/6813 - 0s - loss: 0.7725 - val_loss: 0.7673\n",
      "Epoch 76/1000\n",
      "6813/6813 - 0s - loss: 0.7171 - val_loss: 0.8103\n",
      "Epoch 77/1000\n",
      "6813/6813 - 0s - loss: 0.7163 - val_loss: 0.7585\n",
      "Epoch 78/1000\n",
      "6813/6813 - 0s - loss: 0.7356 - val_loss: 0.7798\n",
      "Epoch 79/1000\n",
      "6813/6813 - 0s - loss: 0.7386 - val_loss: 0.7696\n",
      "Epoch 00079: early stopping\n",
      "1\n",
      "Train on 6813 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6813/6813 - 0s - loss: 78.4600 - val_loss: 2.0364\n",
      "Epoch 2/1000\n",
      "6813/6813 - 0s - loss: 1.9157 - val_loss: 1.8014\n",
      "Epoch 3/1000\n",
      "6813/6813 - 0s - loss: 1.6879 - val_loss: 1.7075\n",
      "Epoch 4/1000\n",
      "6813/6813 - 0s - loss: 1.6221 - val_loss: 1.6577\n",
      "Epoch 5/1000\n",
      "6813/6813 - 0s - loss: 1.5759 - val_loss: 1.6328\n",
      "Epoch 6/1000\n",
      "6813/6813 - 0s - loss: 1.5245 - val_loss: 1.5816\n",
      "Epoch 7/1000\n",
      "6813/6813 - 0s - loss: 1.4777 - val_loss: 1.5114\n",
      "Epoch 8/1000\n",
      "6813/6813 - 0s - loss: 1.4165 - val_loss: 1.4549\n",
      "Epoch 9/1000\n",
      "6813/6813 - 0s - loss: 1.3617 - val_loss: 1.3702\n",
      "Epoch 10/1000\n",
      "6813/6813 - 0s - loss: 1.2923 - val_loss: 1.3133\n",
      "Epoch 11/1000\n",
      "6813/6813 - 0s - loss: 1.2470 - val_loss: 1.3358\n",
      "Epoch 12/1000\n",
      "6813/6813 - 0s - loss: 1.2315 - val_loss: 1.2578\n",
      "Epoch 13/1000\n",
      "6813/6813 - 0s - loss: 1.1724 - val_loss: 1.2228\n",
      "Epoch 14/1000\n",
      "6813/6813 - 0s - loss: 1.1478 - val_loss: 1.1556\n",
      "Epoch 15/1000\n",
      "6813/6813 - 0s - loss: 1.0972 - val_loss: 1.0917\n",
      "Epoch 16/1000\n",
      "6813/6813 - 0s - loss: 1.0811 - val_loss: 1.0900\n",
      "Epoch 17/1000\n",
      "6813/6813 - 0s - loss: 1.0688 - val_loss: 1.0452\n",
      "Epoch 18/1000\n",
      "6813/6813 - 0s - loss: 1.0466 - val_loss: 1.0291\n",
      "Epoch 19/1000\n",
      "6813/6813 - 0s - loss: 1.0148 - val_loss: 1.0176\n",
      "Epoch 20/1000\n",
      "6813/6813 - 0s - loss: 0.9902 - val_loss: 0.9881\n",
      "Epoch 21/1000\n",
      "6813/6813 - 0s - loss: 1.0011 - val_loss: 0.9882\n",
      "Epoch 22/1000\n",
      "6813/6813 - 0s - loss: 0.9732 - val_loss: 0.9633\n",
      "Epoch 23/1000\n",
      "6813/6813 - 0s - loss: 0.9907 - val_loss: 0.9513\n",
      "Epoch 24/1000\n",
      "6813/6813 - 0s - loss: 0.9596 - val_loss: 0.9870\n",
      "Epoch 25/1000\n",
      "6813/6813 - 0s - loss: 0.9477 - val_loss: 1.0298\n",
      "Epoch 26/1000\n",
      "6813/6813 - 0s - loss: 0.9289 - val_loss: 0.9699\n",
      "Epoch 27/1000\n",
      "6813/6813 - 0s - loss: 0.9553 - val_loss: 1.0296\n",
      "Epoch 28/1000\n",
      "6813/6813 - 0s - loss: 0.9264 - val_loss: 0.9118\n",
      "Epoch 29/1000\n",
      "6813/6813 - 0s - loss: 0.9081 - val_loss: 0.8874\n",
      "Epoch 30/1000\n",
      "6813/6813 - 0s - loss: 0.8988 - val_loss: 0.9261\n",
      "Epoch 31/1000\n",
      "6813/6813 - 0s - loss: 0.8851 - val_loss: 0.8764\n",
      "Epoch 32/1000\n",
      "6813/6813 - 0s - loss: 0.8861 - val_loss: 0.9554\n",
      "Epoch 33/1000\n",
      "6813/6813 - 0s - loss: 0.8685 - val_loss: 0.9126\n",
      "Epoch 34/1000\n",
      "6813/6813 - 0s - loss: 0.8662 - val_loss: 0.8299\n",
      "Epoch 35/1000\n",
      "6813/6813 - 0s - loss: 0.8537 - val_loss: 0.8336\n",
      "Epoch 36/1000\n",
      "6813/6813 - 0s - loss: 0.8603 - val_loss: 0.8154\n",
      "Epoch 37/1000\n",
      "6813/6813 - 0s - loss: 0.8118 - val_loss: 0.8293\n",
      "Epoch 38/1000\n",
      "6813/6813 - 0s - loss: 0.8202 - val_loss: 0.7952\n",
      "Epoch 39/1000\n",
      "6813/6813 - 0s - loss: 0.7987 - val_loss: 0.7893\n",
      "Epoch 40/1000\n",
      "6813/6813 - 0s - loss: 0.8017 - val_loss: 0.7795\n",
      "Epoch 41/1000\n",
      "6813/6813 - 0s - loss: 0.8217 - val_loss: 0.8712\n",
      "Epoch 42/1000\n",
      "6813/6813 - 0s - loss: 0.7978 - val_loss: 0.9572\n",
      "Epoch 43/1000\n",
      "6813/6813 - 0s - loss: 0.7921 - val_loss: 0.7535\n",
      "Epoch 44/1000\n",
      "6813/6813 - 0s - loss: 0.7664 - val_loss: 0.8214\n",
      "Epoch 45/1000\n",
      "6813/6813 - 0s - loss: 0.7816 - val_loss: 0.7570\n",
      "Epoch 46/1000\n",
      "6813/6813 - 0s - loss: 0.7821 - val_loss: 0.7774\n",
      "Epoch 47/1000\n",
      "6813/6813 - 0s - loss: 0.7628 - val_loss: 0.9979\n",
      "Epoch 48/1000\n",
      "6813/6813 - 0s - loss: 0.7862 - val_loss: 0.7315\n",
      "Epoch 49/1000\n",
      "6813/6813 - 0s - loss: 0.7374 - val_loss: 0.7298\n",
      "Epoch 50/1000\n",
      "6813/6813 - 0s - loss: 0.7580 - val_loss: 0.7211\n",
      "Epoch 51/1000\n",
      "6813/6813 - 0s - loss: 0.7617 - val_loss: 0.7087\n",
      "Epoch 52/1000\n",
      "6813/6813 - 0s - loss: 0.7261 - val_loss: 0.7082\n",
      "Epoch 53/1000\n",
      "6813/6813 - 0s - loss: 0.7151 - val_loss: 0.7059\n",
      "Epoch 54/1000\n",
      "6813/6813 - 0s - loss: 0.7360 - val_loss: 0.7069\n",
      "Epoch 55/1000\n",
      "6813/6813 - 0s - loss: 0.7595 - val_loss: 0.7072\n",
      "Epoch 56/1000\n",
      "6813/6813 - 0s - loss: 0.7194 - val_loss: 0.7607\n",
      "Epoch 57/1000\n",
      "6813/6813 - 0s - loss: 0.7391 - val_loss: 0.7192\n",
      "Epoch 58/1000\n",
      "6813/6813 - 0s - loss: 0.7167 - val_loss: 0.6819\n",
      "Epoch 59/1000\n",
      "6813/6813 - 0s - loss: 0.7191 - val_loss: 0.6977\n",
      "Epoch 60/1000\n",
      "6813/6813 - 0s - loss: 0.6945 - val_loss: 0.6860\n",
      "Epoch 61/1000\n",
      "6813/6813 - 0s - loss: 0.6869 - val_loss: 0.6746\n",
      "Epoch 62/1000\n",
      "6813/6813 - 0s - loss: 0.6965 - val_loss: 0.6668\n",
      "Epoch 63/1000\n",
      "6813/6813 - 0s - loss: 0.6861 - val_loss: 0.7083\n",
      "Epoch 64/1000\n",
      "6813/6813 - 0s - loss: 0.7024 - val_loss: 0.7117\n",
      "Epoch 65/1000\n",
      "6813/6813 - 0s - loss: 0.6796 - val_loss: 0.7035\n",
      "Epoch 66/1000\n",
      "6813/6813 - 0s - loss: 0.7083 - val_loss: 0.8099\n",
      "Epoch 67/1000\n",
      "6813/6813 - 0s - loss: 0.6734 - val_loss: 0.7593\n",
      "Epoch 68/1000\n",
      "6813/6813 - 0s - loss: 0.6711 - val_loss: 0.6554\n",
      "Epoch 69/1000\n",
      "6813/6813 - 0s - loss: 0.7248 - val_loss: 0.8822\n",
      "Epoch 70/1000\n",
      "6813/6813 - 0s - loss: 0.6882 - val_loss: 0.8163\n",
      "Epoch 71/1000\n",
      "6813/6813 - 0s - loss: 0.7348 - val_loss: 0.6563\n",
      "Epoch 72/1000\n",
      "6813/6813 - 0s - loss: 0.6609 - val_loss: 0.6423\n",
      "Epoch 73/1000\n",
      "6813/6813 - 0s - loss: 0.6762 - val_loss: 0.6617\n",
      "Epoch 74/1000\n",
      "6813/6813 - 0s - loss: 0.7105 - val_loss: 0.7621\n",
      "Epoch 75/1000\n",
      "6813/6813 - 0s - loss: 0.6565 - val_loss: 0.6860\n",
      "Epoch 76/1000\n",
      "6813/6813 - 0s - loss: 0.7013 - val_loss: 0.6542\n",
      "Epoch 77/1000\n",
      "6813/6813 - 0s - loss: 0.6607 - val_loss: 0.6938\n",
      "Epoch 78/1000\n",
      "6813/6813 - 0s - loss: 0.6873 - val_loss: 0.6621\n",
      "Epoch 79/1000\n",
      "6813/6813 - 0s - loss: 0.7042 - val_loss: 0.8442\n",
      "Epoch 00079: early stopping\n",
      "2\n",
      "Train on 6813 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6813/6813 - 0s - loss: 7.2616 - val_loss: 1.6856\n",
      "Epoch 2/1000\n",
      "6813/6813 - 0s - loss: 1.4099 - val_loss: 1.4391\n",
      "Epoch 3/1000\n",
      "6813/6813 - 0s - loss: 1.3300 - val_loss: 1.3912\n",
      "Epoch 4/1000\n",
      "6813/6813 - 0s - loss: 1.2826 - val_loss: 1.3500\n",
      "Epoch 5/1000\n",
      "6813/6813 - 0s - loss: 1.2441 - val_loss: 1.3128\n",
      "Epoch 6/1000\n",
      "6813/6813 - 0s - loss: 1.2325 - val_loss: 1.3941\n",
      "Epoch 7/1000\n",
      "6813/6813 - 0s - loss: 1.2321 - val_loss: 1.2421\n",
      "Epoch 8/1000\n",
      "6813/6813 - 0s - loss: 1.1571 - val_loss: 1.2316\n",
      "Epoch 9/1000\n",
      "6813/6813 - 0s - loss: 1.1169 - val_loss: 1.1939\n",
      "Epoch 10/1000\n",
      "6813/6813 - 0s - loss: 1.1295 - val_loss: 1.2020\n",
      "Epoch 11/1000\n",
      "6813/6813 - 0s - loss: 1.0429 - val_loss: 1.1333\n",
      "Epoch 12/1000\n",
      "6813/6813 - 0s - loss: 1.0199 - val_loss: 1.0680\n",
      "Epoch 13/1000\n",
      "6813/6813 - 0s - loss: 1.0161 - val_loss: 1.0344\n",
      "Epoch 14/1000\n",
      "6813/6813 - 0s - loss: 0.9727 - val_loss: 1.0057\n",
      "Epoch 15/1000\n",
      "6813/6813 - 0s - loss: 0.9621 - val_loss: 1.0833\n",
      "Epoch 16/1000\n",
      "6813/6813 - 0s - loss: 1.0114 - val_loss: 0.9595\n",
      "Epoch 17/1000\n",
      "6813/6813 - 0s - loss: 0.9571 - val_loss: 1.0012\n",
      "Epoch 18/1000\n",
      "6813/6813 - 0s - loss: 0.8999 - val_loss: 0.9245\n",
      "Epoch 19/1000\n",
      "6813/6813 - 0s - loss: 0.8900 - val_loss: 0.8883\n",
      "Epoch 20/1000\n",
      "6813/6813 - 0s - loss: 0.8798 - val_loss: 0.8770\n",
      "Epoch 21/1000\n",
      "6813/6813 - 0s - loss: 0.8316 - val_loss: 0.9127\n",
      "Epoch 22/1000\n",
      "6813/6813 - 0s - loss: 0.8296 - val_loss: 0.8891\n",
      "Epoch 23/1000\n",
      "6813/6813 - 0s - loss: 0.8094 - val_loss: 0.8269\n",
      "Epoch 24/1000\n",
      "6813/6813 - 0s - loss: 0.8134 - val_loss: 0.8099\n",
      "Epoch 25/1000\n",
      "6813/6813 - 0s - loss: 0.8326 - val_loss: 0.8261\n",
      "Epoch 26/1000\n",
      "6813/6813 - 0s - loss: 0.7805 - val_loss: 0.8718\n",
      "Epoch 27/1000\n",
      "6813/6813 - 0s - loss: 0.8223 - val_loss: 0.8162\n",
      "Epoch 28/1000\n",
      "6813/6813 - 0s - loss: 0.7650 - val_loss: 0.8155\n",
      "Epoch 29/1000\n",
      "6813/6813 - 0s - loss: 0.7904 - val_loss: 1.0798\n",
      "Epoch 30/1000\n",
      "6813/6813 - 0s - loss: 0.8020 - val_loss: 0.7716\n",
      "Epoch 31/1000\n",
      "6813/6813 - 0s - loss: 0.7930 - val_loss: 0.7540\n",
      "Epoch 32/1000\n",
      "6813/6813 - 0s - loss: 0.8088 - val_loss: 0.7700\n",
      "Epoch 33/1000\n",
      "6813/6813 - 0s - loss: 0.7634 - val_loss: 0.7750\n",
      "Epoch 34/1000\n",
      "6813/6813 - 0s - loss: 0.7869 - val_loss: 0.7700\n",
      "Epoch 35/1000\n",
      "6813/6813 - 0s - loss: 0.7521 - val_loss: 0.7488\n",
      "Epoch 36/1000\n",
      "6813/6813 - 0s - loss: 0.7140 - val_loss: 0.7411\n",
      "Epoch 37/1000\n",
      "6813/6813 - 0s - loss: 0.7496 - val_loss: 0.7332\n",
      "Epoch 38/1000\n",
      "6813/6813 - 0s - loss: 0.7960 - val_loss: 0.8338\n",
      "Epoch 39/1000\n",
      "6813/6813 - 0s - loss: 0.7289 - val_loss: 0.8230\n",
      "Epoch 40/1000\n",
      "6813/6813 - 0s - loss: 0.7094 - val_loss: 0.7741\n",
      "Epoch 41/1000\n",
      "6813/6813 - 0s - loss: 0.7591 - val_loss: 0.7451\n",
      "Epoch 42/1000\n",
      "6813/6813 - 0s - loss: 0.7223 - val_loss: 0.7267\n",
      "Epoch 43/1000\n",
      "6813/6813 - 0s - loss: 0.7117 - val_loss: 0.7418\n",
      "Epoch 44/1000\n",
      "6813/6813 - 0s - loss: 0.7621 - val_loss: 0.7069\n",
      "Epoch 45/1000\n",
      "6813/6813 - 0s - loss: 0.7789 - val_loss: 1.2866\n",
      "Epoch 46/1000\n",
      "6813/6813 - 0s - loss: 0.8447 - val_loss: 0.7446\n",
      "Epoch 47/1000\n",
      "6813/6813 - 0s - loss: 0.7545 - val_loss: 0.7021\n",
      "Epoch 48/1000\n",
      "6813/6813 - 0s - loss: 0.7000 - val_loss: 0.6976\n",
      "Epoch 49/1000\n",
      "6813/6813 - 0s - loss: 0.7087 - val_loss: 0.7142\n",
      "Epoch 50/1000\n",
      "6813/6813 - 0s - loss: 0.6706 - val_loss: 0.7644\n",
      "Epoch 51/1000\n",
      "6813/6813 - 0s - loss: 0.6884 - val_loss: 0.7175\n",
      "Epoch 52/1000\n",
      "6813/6813 - 0s - loss: 0.6734 - val_loss: 0.7316\n",
      "Epoch 53/1000\n",
      "6813/6813 - 0s - loss: 0.7478 - val_loss: 0.8061\n",
      "Epoch 54/1000\n",
      "6813/6813 - 0s - loss: 0.6816 - val_loss: 0.7434\n",
      "Epoch 55/1000\n",
      "6813/6813 - 0s - loss: 0.6715 - val_loss: 0.7089\n",
      "Epoch 00055: early stopping\n",
      "3\n",
      "Train on 6813 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6813/6813 - 0s - loss: 701.7864 - val_loss: 10.0184\n",
      "Epoch 2/1000\n",
      "6813/6813 - 0s - loss: 5.8893 - val_loss: 2.0932\n",
      "Epoch 3/1000\n",
      "6813/6813 - 0s - loss: 1.6903 - val_loss: 1.7057\n",
      "Epoch 4/1000\n",
      "6813/6813 - 0s - loss: 1.5169 - val_loss: 1.6148\n",
      "Epoch 5/1000\n",
      "6813/6813 - 0s - loss: 1.4174 - val_loss: 1.5267\n",
      "Epoch 6/1000\n",
      "6813/6813 - 0s - loss: 1.3407 - val_loss: 1.4394\n",
      "Epoch 7/1000\n",
      "6813/6813 - 0s - loss: 1.2808 - val_loss: 1.5441\n",
      "Epoch 8/1000\n",
      "6813/6813 - 0s - loss: 1.2432 - val_loss: 1.4040\n",
      "Epoch 9/1000\n",
      "6813/6813 - 0s - loss: 1.1632 - val_loss: 1.3039\n",
      "Epoch 10/1000\n",
      "6813/6813 - 0s - loss: 1.0937 - val_loss: 1.2025\n",
      "Epoch 11/1000\n",
      "6813/6813 - 0s - loss: 1.0723 - val_loss: 1.2893\n",
      "Epoch 12/1000\n",
      "6813/6813 - 0s - loss: 1.0653 - val_loss: 1.3148\n",
      "Epoch 13/1000\n",
      "6813/6813 - 0s - loss: 1.0043 - val_loss: 1.1004\n",
      "Epoch 14/1000\n",
      "6813/6813 - 0s - loss: 1.0027 - val_loss: 1.0648\n",
      "Epoch 15/1000\n",
      "6813/6813 - 0s - loss: 0.9576 - val_loss: 1.0522\n",
      "Epoch 16/1000\n",
      "6813/6813 - 0s - loss: 0.9556 - val_loss: 1.0649\n",
      "Epoch 17/1000\n",
      "6813/6813 - 0s - loss: 0.9316 - val_loss: 1.0234\n",
      "Epoch 18/1000\n",
      "6813/6813 - 0s - loss: 0.9096 - val_loss: 1.0465\n",
      "Epoch 19/1000\n",
      "6813/6813 - 0s - loss: 0.8879 - val_loss: 0.9714\n",
      "Epoch 20/1000\n",
      "6813/6813 - 0s - loss: 0.8765 - val_loss: 0.9649\n",
      "Epoch 21/1000\n",
      "6813/6813 - 0s - loss: 0.8848 - val_loss: 1.0874\n",
      "Epoch 22/1000\n",
      "6813/6813 - 0s - loss: 0.8788 - val_loss: 0.9333\n",
      "Epoch 23/1000\n",
      "6813/6813 - 0s - loss: 0.8330 - val_loss: 0.9373\n",
      "Epoch 24/1000\n",
      "6813/6813 - 0s - loss: 0.8529 - val_loss: 0.9232\n",
      "Epoch 25/1000\n",
      "6813/6813 - 0s - loss: 0.8252 - val_loss: 0.9259\n",
      "Epoch 26/1000\n",
      "6813/6813 - 0s - loss: 0.8227 - val_loss: 0.8825\n",
      "Epoch 27/1000\n",
      "6813/6813 - 0s - loss: 0.8029 - val_loss: 0.9598\n",
      "Epoch 28/1000\n",
      "6813/6813 - 0s - loss: 0.7975 - val_loss: 0.8739\n",
      "Epoch 29/1000\n",
      "6813/6813 - 0s - loss: 0.7941 - val_loss: 0.9093\n",
      "Epoch 30/1000\n",
      "6813/6813 - 0s - loss: 0.7890 - val_loss: 0.8769\n",
      "Epoch 31/1000\n",
      "6813/6813 - 0s - loss: 0.7910 - val_loss: 0.8941\n",
      "Epoch 32/1000\n",
      "6813/6813 - 0s - loss: 0.7902 - val_loss: 0.8332\n",
      "Epoch 33/1000\n",
      "6813/6813 - 0s - loss: 0.7696 - val_loss: 0.8548\n",
      "Epoch 34/1000\n",
      "6813/6813 - 0s - loss: 0.7532 - val_loss: 0.8331\n",
      "Epoch 35/1000\n",
      "6813/6813 - 0s - loss: 0.7383 - val_loss: 1.0018\n",
      "Epoch 36/1000\n",
      "6813/6813 - 0s - loss: 0.7523 - val_loss: 0.8758\n",
      "Epoch 37/1000\n",
      "6813/6813 - 0s - loss: 0.7334 - val_loss: 0.8800\n",
      "Epoch 38/1000\n",
      "6813/6813 - 0s - loss: 0.7504 - val_loss: 0.7906\n",
      "Epoch 39/1000\n",
      "6813/6813 - 0s - loss: 0.7348 - val_loss: 0.8035\n",
      "Epoch 40/1000\n",
      "6813/6813 - 0s - loss: 0.7314 - val_loss: 0.7760\n",
      "Epoch 41/1000\n",
      "6813/6813 - 0s - loss: 0.7164 - val_loss: 0.7739\n",
      "Epoch 42/1000\n",
      "6813/6813 - 0s - loss: 0.6964 - val_loss: 0.7695\n",
      "Epoch 43/1000\n",
      "6813/6813 - 0s - loss: 0.7195 - val_loss: 0.8260\n",
      "Epoch 44/1000\n",
      "6813/6813 - 0s - loss: 0.7223 - val_loss: 0.7698\n",
      "Epoch 45/1000\n",
      "6813/6813 - 0s - loss: 0.6949 - val_loss: 0.7495\n",
      "Epoch 46/1000\n",
      "6813/6813 - 0s - loss: 0.6995 - val_loss: 0.7774\n",
      "Epoch 47/1000\n",
      "6813/6813 - 0s - loss: 0.7513 - val_loss: 0.8012\n",
      "Epoch 48/1000\n",
      "6813/6813 - 0s - loss: 0.6930 - val_loss: 0.7461\n",
      "Epoch 49/1000\n",
      "6813/6813 - 0s - loss: 0.6661 - val_loss: 0.7393\n",
      "Epoch 50/1000\n",
      "6813/6813 - 0s - loss: 0.6986 - val_loss: 0.7410\n",
      "Epoch 51/1000\n",
      "6813/6813 - 0s - loss: 0.6930 - val_loss: 0.7228\n",
      "Epoch 52/1000\n",
      "6813/6813 - 0s - loss: 0.6947 - val_loss: 0.7683\n",
      "Epoch 53/1000\n",
      "6813/6813 - 0s - loss: 0.6609 - val_loss: 0.7265\n",
      "Epoch 54/1000\n",
      "6813/6813 - 0s - loss: 0.6766 - val_loss: 0.7251\n",
      "Epoch 55/1000\n",
      "6813/6813 - 0s - loss: 0.6989 - val_loss: 0.7541\n",
      "Epoch 56/1000\n",
      "6813/6813 - 0s - loss: 0.6716 - val_loss: 0.7108\n",
      "Epoch 57/1000\n",
      "6813/6813 - 0s - loss: 0.6507 - val_loss: 0.7031\n",
      "Epoch 58/1000\n",
      "6813/6813 - 0s - loss: 0.6967 - val_loss: 0.7753\n",
      "Epoch 59/1000\n",
      "6813/6813 - 0s - loss: 0.6435 - val_loss: 0.7951\n",
      "Epoch 60/1000\n",
      "6813/6813 - 0s - loss: 0.6502 - val_loss: 0.7088\n",
      "Epoch 61/1000\n",
      "6813/6813 - 0s - loss: 0.6800 - val_loss: 1.0321\n",
      "Epoch 62/1000\n",
      "6813/6813 - 0s - loss: 0.6648 - val_loss: 0.6957\n",
      "Epoch 63/1000\n",
      "6813/6813 - 0s - loss: 0.6452 - val_loss: 0.8065\n",
      "Epoch 64/1000\n",
      "6813/6813 - 0s - loss: 0.6489 - val_loss: 0.7689\n",
      "Epoch 65/1000\n",
      "6813/6813 - 0s - loss: 0.6628 - val_loss: 0.8835\n",
      "Epoch 66/1000\n",
      "6813/6813 - 0s - loss: 0.6557 - val_loss: 0.7061\n",
      "Epoch 67/1000\n",
      "6813/6813 - 0s - loss: 0.6459 - val_loss: 0.8331\n",
      "Epoch 68/1000\n",
      "6813/6813 - 0s - loss: 0.6713 - val_loss: 0.8196\n",
      "Epoch 69/1000\n",
      "6813/6813 - 0s - loss: 0.6292 - val_loss: 0.7013\n",
      "Epoch 00069: early stopping\n",
      "4\n",
      "Train on 6813 samples, validate on 2921 samples\n",
      "Epoch 1/1000\n",
      "6813/6813 - 0s - loss: 4669.0656 - val_loss: 339.0934\n",
      "Epoch 2/1000\n",
      "6813/6813 - 0s - loss: 41.7283 - val_loss: 2.9748\n",
      "Epoch 3/1000\n",
      "6813/6813 - 0s - loss: 2.2859 - val_loss: 2.2152\n",
      "Epoch 4/1000\n",
      "6813/6813 - 0s - loss: 2.0205 - val_loss: 2.1574\n",
      "Epoch 5/1000\n",
      "6813/6813 - 0s - loss: 1.9800 - val_loss: 2.1254\n",
      "Epoch 6/1000\n",
      "6813/6813 - 0s - loss: 1.9391 - val_loss: 2.0948\n",
      "Epoch 7/1000\n",
      "6813/6813 - 0s - loss: 1.8904 - val_loss: 2.0284\n",
      "Epoch 8/1000\n",
      "6813/6813 - 0s - loss: 1.8064 - val_loss: 1.9353\n",
      "Epoch 9/1000\n",
      "6813/6813 - 0s - loss: 1.7275 - val_loss: 1.9618\n",
      "Epoch 10/1000\n",
      "6813/6813 - 0s - loss: 1.6313 - val_loss: 1.7171\n",
      "Epoch 11/1000\n",
      "6813/6813 - 0s - loss: 1.4755 - val_loss: 1.5977\n",
      "Epoch 12/1000\n",
      "6813/6813 - 0s - loss: 1.3199 - val_loss: 1.4140\n",
      "Epoch 13/1000\n",
      "6813/6813 - 0s - loss: 1.1881 - val_loss: 1.2850\n",
      "Epoch 14/1000\n",
      "6813/6813 - 0s - loss: 1.1094 - val_loss: 1.1821\n",
      "Epoch 15/1000\n",
      "6813/6813 - 0s - loss: 1.0436 - val_loss: 1.2651\n",
      "Epoch 16/1000\n",
      "6813/6813 - 0s - loss: 0.9786 - val_loss: 1.0676\n",
      "Epoch 17/1000\n",
      "6813/6813 - 0s - loss: 0.9332 - val_loss: 1.0054\n",
      "Epoch 18/1000\n",
      "6813/6813 - 0s - loss: 0.9022 - val_loss: 0.9913\n",
      "Epoch 19/1000\n",
      "6813/6813 - 0s - loss: 0.8977 - val_loss: 1.0740\n",
      "Epoch 20/1000\n",
      "6813/6813 - 0s - loss: 0.8671 - val_loss: 0.9383\n",
      "Epoch 21/1000\n",
      "6813/6813 - 0s - loss: 0.8277 - val_loss: 0.9234\n",
      "Epoch 22/1000\n",
      "6813/6813 - 0s - loss: 0.7927 - val_loss: 0.8506\n",
      "Epoch 23/1000\n",
      "6813/6813 - 0s - loss: 0.8103 - val_loss: 0.8631\n",
      "Epoch 24/1000\n",
      "6813/6813 - 0s - loss: 0.7656 - val_loss: 0.8275\n",
      "Epoch 25/1000\n",
      "6813/6813 - 0s - loss: 0.7811 - val_loss: 0.8294\n",
      "Epoch 26/1000\n",
      "6813/6813 - 0s - loss: 0.7771 - val_loss: 0.8175\n",
      "Epoch 27/1000\n",
      "6813/6813 - 0s - loss: 0.7576 - val_loss: 0.8890\n",
      "Epoch 28/1000\n",
      "6813/6813 - 0s - loss: 0.7760 - val_loss: 0.8182\n",
      "Epoch 29/1000\n",
      "6813/6813 - 0s - loss: 0.7485 - val_loss: 0.8085\n",
      "Epoch 30/1000\n",
      "6813/6813 - 0s - loss: 0.7488 - val_loss: 0.8604\n",
      "Epoch 31/1000\n",
      "6813/6813 - 0s - loss: 0.7784 - val_loss: 0.8034\n",
      "Epoch 32/1000\n",
      "6813/6813 - 0s - loss: 0.7560 - val_loss: 0.8343\n",
      "Epoch 33/1000\n",
      "6813/6813 - 0s - loss: 0.7573 - val_loss: 0.8101\n",
      "Epoch 34/1000\n",
      "6813/6813 - 0s - loss: 0.7378 - val_loss: 0.8060\n",
      "Epoch 35/1000\n",
      "6813/6813 - 0s - loss: 0.7313 - val_loss: 0.7854\n",
      "Epoch 36/1000\n",
      "6813/6813 - 0s - loss: 0.7654 - val_loss: 0.8500\n",
      "Epoch 37/1000\n",
      "6813/6813 - 0s - loss: 0.7503 - val_loss: 0.7815\n",
      "Epoch 38/1000\n",
      "6813/6813 - 0s - loss: 0.7318 - val_loss: 0.8138\n",
      "Epoch 39/1000\n",
      "6813/6813 - 0s - loss: 0.7244 - val_loss: 0.7817\n",
      "Epoch 40/1000\n",
      "6813/6813 - 0s - loss: 0.7169 - val_loss: 0.7816\n",
      "Epoch 41/1000\n",
      "6813/6813 - 0s - loss: 0.7218 - val_loss: 0.7858\n",
      "Epoch 42/1000\n",
      "6813/6813 - 0s - loss: 0.7618 - val_loss: 0.8795\n",
      "Epoch 43/1000\n",
      "6813/6813 - 0s - loss: 0.7484 - val_loss: 0.8000\n",
      "Epoch 44/1000\n",
      "6813/6813 - 0s - loss: 0.7181 - val_loss: 0.7639\n",
      "Epoch 45/1000\n",
      "6813/6813 - 0s - loss: 0.7142 - val_loss: 0.7990\n",
      "Epoch 46/1000\n",
      "6813/6813 - 0s - loss: 0.7296 - val_loss: 0.7858\n",
      "Epoch 47/1000\n",
      "6813/6813 - 0s - loss: 0.7116 - val_loss: 0.7588\n",
      "Epoch 48/1000\n",
      "6813/6813 - 0s - loss: 0.7082 - val_loss: 0.7881\n",
      "Epoch 49/1000\n",
      "6813/6813 - 0s - loss: 0.7330 - val_loss: 0.7607\n",
      "Epoch 50/1000\n",
      "6813/6813 - 0s - loss: 0.7158 - val_loss: 0.7643\n",
      "Epoch 51/1000\n",
      "6813/6813 - 0s - loss: 0.7273 - val_loss: 0.8631\n",
      "Epoch 52/1000\n",
      "6813/6813 - 0s - loss: 0.7152 - val_loss: 0.7923\n",
      "Epoch 53/1000\n",
      "6813/6813 - 0s - loss: 0.6970 - val_loss: 0.7700\n",
      "Epoch 54/1000\n",
      "6813/6813 - 0s - loss: 0.7079 - val_loss: 0.7827\n",
      "Epoch 00054: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n",
      "[[20.919703]\n",
      " [52.062847]\n",
      " [55.85175 ]\n",
      " ...\n",
      " [86.928635]\n",
      " [51.686558]\n",
      " [47.755024]]\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=r\"C:\\Users\\siris\\OneDrive\\Desktop\\215\\mini-project2\\best_weights5.hdf5\", verbose=0, save_best_only=True)\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=7, verbose=1, mode='auto')\n",
    "     # save best model\n",
    "\n",
    "    # batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test), batch_size= 128, callbacks=[monitor,checkpointer],verbose=2,epochs=1000)\n",
    "print('Training finished...Loading the best model')  \n",
    "print()\n",
    "model.load_weights(r\"C:\\Users\\siris\\OneDrive\\Desktop\\215\\mini-project2\\best_weights5.hdf5\") # load weights from best model\n",
    "\n",
    "# Predict and measure RMSE\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "#pred = np.argmax(pred,axis=1) # raw probabilities to choose class (highest probability)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 0.8014251589775085\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test, sort=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
